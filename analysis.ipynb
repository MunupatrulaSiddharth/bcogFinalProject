{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e662369a-2e5f-4bd8-85d1-fe95a1f3de42",
   "metadata": {},
   "source": [
    " # Mental Representations of Psychological Disorders: A Reverse Correlation Approach\n",
    "\n",
    " ## Abstract\n",
    "\n",
    "- Mental health stigma remains a pervasive societal issue, influencing interpersonal behavior, access to care, and policy support. While explicit attitudes have been widely studied, less is known about how individuals visually conceptualize mental illness in others. This study investigates the mental representations people hold of various psychological disorders by leveraging a reverse correlation approach to face perception.\n",
    "\n",
    "- Participants completed a categorization task where they judged AI-generated faces for resemblance to individuals with specific mental health conditions (depression, anxiety, bipolar disorder, and PTSD). The images were randomly sampled from a generative adversarial network trained on neutral human faces, allowing systematic mapping of participants visual intuitions. From these responses, individual-level visual prototypes were estimated.\n",
    "\n",
    "- These prototypes were analyzed using computational models of social perception to assess how visual representations align with attributes like trustworthiness, dominance, and attractiveness. The strength and valence of these impressions were related to participants self-reported stigma toward mental illness.\n",
    "\n",
    "- Results demonstrate that visual representations of mental illness systematically differ from non-illness categories along socially relevant dimensions, and these differences scale with individual variation in stigma. By making implicit visual stereotypes explicit, this study offers a novel framework for quantifying how social bias becomes encoded in mental imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec3b87-3842-4f5d-adb4-0ef9c9310ed7",
   "metadata": {},
   "source": [
    "\n",
    "## Introduction\n",
    "\n",
    "### Background and Significance\n",
    "\n",
    "Mental health stigma constitutes a significant barrier to treatment seeking and social integration for individuals with psychological disorders. While substantial research has examined explicit stereotypes through self-report measures, the visual components of these stereotypes remain understudied. The human brain relies heavily on facial cues when forming social judgments (Todorov et al., 2015), making visual representations a critical yet overlooked aspect of mental illness stigma.\n",
    "\n",
    "Reverse correlation techniques have emerged as a powerful tool for revealing the mental templates underlying social judgments. This method involves having participants make judgments about randomly varying stimuli, then statistically reconstructing the implicit template guiding those judgments. Applied to face perception, this approach can reveal how people visually conceptualize social categories - including stigmatized groups.\n",
    "\n",
    "### Current Study\n",
    "\n",
    "This investigation employs a novel combination of generative adversarial networks (GANs) and reverse correlation to:\n",
    "1. Map visual prototypes for four psychological disorders (MDD, GAD, BPD, PTSD)\n",
    "2. Quantify how these representations differ from neutral faces\n",
    "3. Examine relationships between prototype characteristics and explicit stigma measures\n",
    "\n",
    "The study advances stigma research by moving beyond verbal reports to examine the visual basis of stereotyping, with implications for anti-stigma interventions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49fb4a9-c653-4492-b8d8-9231d163dfef",
   "metadata": {},
   "source": [
    "\n",
    "## Methods\n",
    "\n",
    "### Participants\n",
    "\n",
    "A total of N=300 participants will be recruited through university subject pools. Participants completed:\n",
    "- Reverse correlation face judgment task\n",
    "\n",
    "- For each image, participants must select one of three options:\n",
    "  - `{X}` (e.g., a specific judgment assigned to the participant)\n",
    "  - `not {X}`\n",
    "  - `not sure`\n",
    "- The judgment `{X}` is assigned to each participant based on the experimental cond\n",
    "\n",
    "- Demographic questionnaire\n",
    "- Mental Illness Stigma Scale (MISS; α=.89)\n",
    "- Debriefingi\n",
    "tion.\n",
    "Sample size was determined through power analysis for planned within-subject comparisons of face prototypes.\n",
    "\n",
    "### Stimuli\n",
    "\n",
    "Faces were generated using StyleGAN2 (Karras et al., 2020) trained on the FFHQ dataset. From the latent space, we sampled 300 base faces meeting criteria for:\n",
    "- Neutral emotional expression\n",
    "- Balanced gender presentation\n",
    "- Diverse racial/ethnic appea\n",
    "- The aim is to recruit **30 participants per experimental condition**.\n",
    "- The total target sample size is **120-150 participants across all conditions**.rance\n",
    "\n",
    "Each face was rendered at 512×512 resolution with consistent lighting and background.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ab5ba-be0a-4f3c-af29-b240edd311d6",
   "metadata": {},
   "source": [
    "\n",
    "### Procedure\n",
    "\n",
    "The experiment consisted of three phases:\n",
    "\n",
    "1. **Training Phase (10 trials)**\n",
    "   - Familiarized participants with task requirements\n",
    "   - Provided examples of \"prototypical\" faces (not used in main task)\n",
    "\n",
    "2. **Main Task (300 trials)**\n",
    "   - Each trial presented one randomly generated face\n",
    "   - Participants judged whether face resembled someone with:\n",
    "     - Their assigned condition (e.g., \"PTSD\")\n",
    "     - \"Not [condition]\"\n",
    "     - \"Not sure\"\n",
    "   - 10% of trials were repeats for reliability assessment\n",
    "\n",
    "3. **Survey Measures**\n",
    "   - Demographic questionnaire\n",
    "   - Stigma scale (MISS)\n",
    "   - Debriefing questions about task strategies\n",
    "\n",
    "Total session duration averaged 45 minutes. Participants received course credit or $15 compensation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69db9ca-7a89-4550-8ecc-fea3e33d663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%matplotlib inline\n",
    "import os, sys, subprocess\n",
    "import ctypes\n",
    "\n",
    "\n",
    "\n",
    "# Ensure that it can see `fused.so`, `libcudart.so.10.0`, `libcudnn_cnn_infer.so.8` and `libcuda.so`\n",
    "# Also make sure to update your .bashrc LD_LIBRARY_PATH to include the nonsense below.\n",
    "my_env = os.environ.copy()\n",
    "my_home_dir = \"/home/stefanu/\"\n",
    "paths_to_include = [\n",
    "    f\"{my_home_dir}envs/pytorch/lib/python3.10/site-packages/nvidia/cudnn/lib\",\n",
    "    f\"{my_home_dir}envs/pytorch/lib/python3.10/site-packages/torch/lib\",\n",
    "    f\"{my_home_dir}envs/pytorch/bin\",\n",
    "    f\"{my_home_dir}envs/pytorch/lib\",\n",
    "    f\"{my_home_dir}envs/pytorch/targets/x86_64-linux/include\",\n",
    "    f\"{my_home_dir}envs/pytorch/lib/stubs\",\n",
    "]\n",
    "paths_to_include_string = \":\".join(paths_to_include)\n",
    "my_env[\"PATH\"] = f\"{paths_to_include_string}:\" + my_env[\"PATH\"]\n",
    "my_env[\"CPATH\"] = f\"{my_home_dir}envs/pytorch/lib/python3.10/site-packages/nvidia/cudnn/lib:{my_home_dir}envs/pytorch/targets/x86_64-linux/include:{my_home_dir}envs/pytorch-kai/lib/python3.10/site-packages/torch/lib\"\n",
    "my_env[\"LD_LIBRARY_PATH\"] = f\"{my_home_dir}envs/pytorch/lib/python3.10/site-packages/nvidia/cudnn/lib:{my_home_dir}envs/pytorch-kai/lib/stubs:{my_home_dir}envs/pytorch-kai/lib/python3.10/site-packages/torch/lib:{my_home_dir}envs/pytorch-kai/targets/x86_64-linux/lib:{my_env.get('LD_LIBRARY_PATH')}\"\n",
    "\n",
    "os.environ.update(my_env)\n",
    "\n",
    "ctypes.CDLL(f\"{my_home_dir}envs/pytorch/lib/python3.10/site-packages/nvidia/cudnn/lib/libcudnn_cnn_infer.so.8\", mode=ctypes.RTLD_GLOBAL)\n",
    "# ctypes.CDLL(f'{my_home_dir}envs/pytorch-kai/lib/python3.10/site-packages/torch/lib/libcudart.so.10.0', mode=ctypes.RTLD_GLOBAL) # file doesn't exist\n",
    "\n",
    "from ipywidgets import interact\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.display import display\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import pytz\n",
    "import janitor\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b508a21-dfa3-47cf-9547-19c7360b93bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = Path(f\"{my_home_dir}repos/modeling-tools/\")\n",
    "ckpt = main_dir / \"pretrained\" / \"NAMFHQ-config-f-004000.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8da6dd-c151-4386-8b40-069e2913e516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cy36/envs/pytorch/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3ce791b-6d9f-4b55-bc8d-65d0bcee30fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cy36/envs/pytorch/lib/python3.10/site-packages/torch/utils/cpp_extension.py:25: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import packaging  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StyleGAN2: Optimized CUDA op FusedLeakyReLU available. Compiling...\n",
      "StyleGAN2: Optimized CUDA op UpFirDn2d available. Compiling...\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from Generators import *\n",
    "from Projectors import *\n",
    "\n",
    "from Config import BaseGeneratorOpts, BaseProjectorOpts, FeatureStyleEncoderOpts, Pixel2Style2PixelOpts\n",
    "from EncoderDecoder import EncoderDecoder\n",
    "from Models import MultiAttributeModel\n",
    "from utils.common import tensor2im, concat_imgs, convert_tensor_to_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc30732f-fdea-4fbc-bf05-63cc6b8173c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_generator = StyleGAN2(BaseGeneratorOpts(ckpt=ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0996ee3-9413-438d-9be2-94b321c52c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No align_ckpt specified, using default:  ./pretrained/shape_predictor_68_face_landmarks.dat\n"
     ]
    }
   ],
   "source": [
    "base_projector = BaseProjector(\n",
    "    generator=base_generator.generator,\n",
    "    projector_opts=BaseProjectorOpts(\n",
    "        ckpt=ckpt,\n",
    "        step=1000,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24bb8b67-fcb7-49c2-84a6-321696c68816",
   "metadata": {},
   "outputs": [],
   "source": [
    "ed = EncoderDecoder(generator=base_generator, projector=base_projector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381346d-e8b1-43f3-958e-6bf6f84b08b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiAttributeModel()\n",
    "model.load(\"/home/stefanu/repos/modeling-tools/models/2024-01-29_omnibus_model.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc902a4-2878-4f54-a755-06b79099d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "utc = pytz.UTC\n",
    "\n",
    "# ROOT_PATH = Path(\"/projects/illinois/las/psych/stefanu/projects/reverse-correlation/helper-ses-mindworks/\")\n",
    "ROOT_PATH = Path(\"/home/stefanu/repos/modeling-tools/output\")\n",
    "DATE_PATH = Path(\"2025-04-29/\")\n",
    "DATA_PATH = Path(\"/home/stefanu/repos/modeling-tools/notebooks\")  # data from jspsych\n",
    "DATA_FILE = \"Data/jspsych_data.csv\"\n",
    "LATENT_PATH = ROOT_PATH / \"Latents\"  # path to dlatents of rc images\n",
    "SAVE_PATH = (\n",
    "    ROOT_PATH / DATE_PATH / \"results\"\n",
    ")  # where you want to save the images/arrays/latents; each subject gets their own folder\n",
    "LEVELS = [\"negative\", \"positive\"]\n",
    "CONDITION_DICT = {\n",
    "    \"mdd\": \"MDD\",\n",
    "    \"bpd\": \"BPD\", \n",
    "    \"gad\": \"GAD\",\n",
    "    \"ptsd\": \"PTSD\"\n",
    "}\n",
    "CONDITIONS = list(CONDITION_DICT.values())\n",
    "CATEGORY_LABEL_DICT = {\n",
    "    \"positive\": \"yes\",\n",
    "    \"negative\": \"no\",\n",
    "    \"neither\": \"not sure\",\n",
    "}\n",
    "\n",
    "CONDITION_MAP = {\n",
    "    'gad': 'GAD',\n",
    "    'mdd': 'MDD', \n",
    "    'bpd': 'BPD',\n",
    "    'ptsd': 'PTSD'\n",
    "}\n",
    "\n",
    "\n",
    "FIGURE_PATH = SAVE_PATH / \"figures\"\n",
    "SEED = 628884\n",
    "\n",
    "IDS_TO_EXCLUDE = [\n",
    "    \"XXX\",\n",
    "    \"95165\"\n",
    "]\n",
    "modeling_tools_dir = \"../repos/modeling-tools/\"\n",
    "modeling_tools_dir = Path(modeling_tools_dir)\n",
    "Path(SAVE_PATH).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109fe9b6-593e-457b-a946-91379d9d57ea",
   "metadata": {},
   "source": [
    "### Data Processing Pipeline\n",
    "\n",
    "The analysis involved multiple stages of data transformation and quality control:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca9d9e-d636-41a4-ae94-0b53d1756f18",
   "metadata": {},
   "source": [
    "\n",
    "#### 1. Initial Data Loading and Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4808f7de-99eb-4eb0-a239-14a5b0323829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=DATA_PATH, data_file=DATA_FILE):\n",
    "    return pd.read_csv(data_dir / data_file).clean_names(case_type=\"snake\")\n",
    "\n",
    "\n",
    "def load_rc_latents(path=LATENT_PATH):\n",
    "    return np.load(path / \"latents.npz\")[\"data\"]\n",
    "\n",
    "\n",
    "def get_concat_h_multi_resize(im_list, resample=Image.BICUBIC):\n",
    "    min_height = min(im.height for im in im_list)\n",
    "    im_list_resize = [\n",
    "        \n",
    "        im.resize(\n",
    "            (int(im.width * min_height / im.height), min_height), resample=resample\n",
    "        )\n",
    "        for im in im_list\n",
    "    ]\n",
    "    total_width = sum(im.width for im in im_list_resize)\n",
    "    dst = Image.new(\"RGB\", (total_width, min_height))\n",
    "    pos_x = 0\n",
    "    for im in im_list_resize:\n",
    "        dst.paste(im, (pos_x, 0))\n",
    "        pos_x += im.width\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1980ff-306d-4fac-95c8-916d0752d7b6",
   "metadata": {},
   "source": [
    "#### 2. Data Quality Control Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86022329-ad5b-44b2-be17-a19d34632cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_screen_dimensions(df):\n",
    "    \"\"\"\n",
    "    Fill in missing screen_width and screen_height values for each worker_id\n",
    "    by copying values from the first row where they appear.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with worker_id, screen_width, screen_height columns,\n",
    "                          where dimensions are only populated in the first row per worker.\n",
    "                          \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with screen dimensions filled for all rows per worker.\n",
    "    \"\"\"\n",
    "    if not all(col in df.columns for col in [\"worker_id\", \"screen_width\", \"screen_height\"]):\n",
    "        print(\"Warning: Missing required columns. Cannot broadcast screen dimensions.\")\n",
    "        return df\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    result_df = df.copy()\n",
    "    \n",
    "    # Use first_valid_index and transform\n",
    "    for dim_col in [\"screen_width\", \"screen_height\"]:\n",
    "        # Get first non-null value for each worker_id\n",
    "        first_values = df.groupby(\"worker_id\")[dim_col].first()\n",
    "        # Map those values back to all rows for that worker\n",
    "        result_df[dim_col] = result_df[\"worker_id\"].map(first_values)\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "\n",
    "def calculate_reliability(df, expected_pairs=30):\n",
    "    \"\"\"\n",
    "    \n",
    "    Calculates test-retest reliability for each worker based on repeated stimuli,\n",
    "\n",
    "    checking for the expected number of pairs.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing experiment data with columns\n",
    "\n",
    "        'worker_id', 'stimulus_number', 'repeat', and 'response_label'.\n",
    "\n",
    "        expected_pairs (int): The expected number of repeated stimuli pairs per worker.\n",
    "    \n",
    "    Returns:\n",
    "       pd.Series: Series mapping worker_id to their test-retest Pearson correlation.\n",
    "        \n",
    "       Returns np.nan for workers who don't have exactly expected_pairs,\n",
    "\n",
    "       have zero variance in responses, or other calculation issues.\n",
    "    \"\"\"\n",
    "    # Filter to only reverse correlation trials\n",
    "    rc_data = df[df['trial_type'] == 'single-stim-rev-cor-trial'].copy()\n",
    "    \n",
    "    # Clean repeat column\n",
    "    rc_data['repeat'] = rc_data['repeat'].replace(\n",
    "    {'True': True, 'False': False, 'true': True, 'false': False}\n",
    "    ).astype(bool)\n",
    "    \n",
    "    # Comprehensive response mapping\n",
    "    response_map = {\n",
    "        \"GAD\": 1, \"no GAD\": -1, \n",
    "        \"MDD\": 1, \"no MDD\": -1,\n",
    "        \"PTSD\": 1, \"no PTSD\": -1, \n",
    "        \"BPD\": 1, \"no BPD\": -1,\n",
    "        \"yes\": 1, \"no\": -1, \"not sure\": 0\n",
    "    }\n",
    "    rc_data['score'] = rc_data['response_label'].map(response_map)\n",
    "    rc_data = rc_data.dropna(subset=['score'])\n",
    "    \n",
    "    # Group by participant\n",
    "    reliability_scores = {}\n",
    "    \n",
    "    for worker_id, worker_data in rc_data.groupby('worker_id'):\n",
    "        # Get all stimuli with exactly 2 presentations (1 first, 1 repeat)\n",
    "        stimulus_counts = worker_data['stimulus_number'].value_counts()\n",
    "        paired_stimuli = stimulus_counts[stimulus_counts == 2].index\n",
    "        \n",
    "        # Verify proper pairing (exactly 1 first and 1 repeat presentation)\n",
    "        valid_pairs = []\n",
    "        for stim in paired_stimuli:\n",
    "            stim_data = worker_data[worker_data['stimulus_number'] == stim]\n",
    "            first = stim_data[~stim_data['repeat']]\n",
    "            repeat = stim_data[stim_data['repeat']]\n",
    "            \n",
    "            if len(first) == 1 and len(repeat) == 1:\n",
    "                valid_pairs.append((\n",
    "                    first.iloc[0]['score'],\n",
    "                    repeat.iloc[0]['score']\n",
    "                ))\n",
    "        \n",
    "        # Calculate reliability if we have sufficient pairs\n",
    "        if len(valid_pairs) >= 2:\n",
    "            try:\n",
    "                first_resp, repeat_resp = zip(*valid_pairs)\n",
    "                corr = pearsonr(first_resp, repeat_resp)[0]\n",
    "                \n",
    "                # Check if we got the expected number of pairs\n",
    "                if len(valid_pairs) != expected_pairs:\n",
    "                    print(f\"Warning: {worker_id} has {len(valid_pairs)} pairs (expected {expected_pairs})\")\n",
    "                \n",
    "                reliability_scores[worker_id] = corr\n",
    "            except:\n",
    "                reliability_scores[worker_id] = np.nan\n",
    "        else:\n",
    "            reliability_scores[worker_id] = np.nan\n",
    "    \n",
    "    return pd.Series(reliability_scores, name='pearson_r')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_main_data(data, include_repeat_data=True):\n",
    "    \"\"\"\n",
    "    Processes experiment data and returns the main experiment data.\n",
    "\n",
    "\n",
    "\n",
    "    Args:\n",
    "\n",
    "        data (pd.DataFrame): Raw DataFrame from experiment data.\n",
    "\n",
    "        include_repeat_data (bool): If True, includes repeat trials for reliable\n",
    "\n",
    "                                     participants in the output 'main_data'.\n",
    "\n",
    "                                     If False, removes repeat trials.\n",
    "\n",
    "        expected_repeat_pairs (int): Expected number of stimulus pairs for reliability check.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        pd.DataFrame: Filtered and cleaned DataFrame for all participants.\n",
    "    \"\"\"\n",
    "    # Filter by experiment phase\n",
    "    valid_phases = [\"main\", \"main_repeat\"]\n",
    "    main_data = data.loc[data[\"experiment_phase\"].isin(valid_phases)].copy()\n",
    "    \n",
    "    if main_data.empty:\n",
    "        print(\"Warning: No data found for experiment_phase == 'main'.\")\n",
    "        return pd.DataFrame()  \n",
    "    \n",
    "    # Convert times\n",
    "    try:\n",
    "        main_data[\"start_time\"] = pd.to_datetime(main_data[\"start_time\"])\n",
    "        main_data[\"end_time\"] = pd.to_datetime(main_data[\"end_time\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not convert time columns: {e}\")\n",
    "    \n",
    "    # Get first session per worker\n",
    "    if \"start_time\" in main_data.columns and \"anon_id\" in main_data.columns:\n",
    "        min_start_times = main_data.groupby(\"anon_id\")[\"start_time\"].min()\n",
    "        main_data = main_data.merge(min_start_times.rename(\"min_start_time\"), \n",
    "                                  on=\"anon_id\", how=\"left\")\n",
    "        main_data = main_data.loc[main_data[\"start_time\"] == main_data[\"min_start_time\"]]\n",
    "        main_data = main_data.drop(columns=[\"min_start_time\"])\n",
    "    \n",
    "    # Apply repeat data filtering\n",
    "    if not include_repeat_data:\n",
    "        main_data = main_data.loc[~main_data[\"repeat\"]]\n",
    "    \n",
    "    # Clean stimulus info\n",
    "    if \"stimulus\" in main_data.columns:\n",
    "        main_data[\"stimulus\"] = main_data[\"stimulus\"].str.replace(\"src/images/main/\", \"\", regex=False)\n",
    "        main_data[\"latent\"] = main_data[\"stimulus\"].str.replace(\".jpg\", \".npy\", regex=False)\n",
    "        main_data[\"stimulus_index\"] = pd.to_numeric(\n",
    "            main_data[\"stimulus\"].str.replace(\".jpg\", \"\", regex=False), \n",
    "            errors=\"coerce\"\n",
    "        )\n",
    "    \n",
    "    return main_data  \n",
    "\n",
    "\n",
    "def clean_data(data, ids_to_exclude=IDS_TO_EXCLUDE):\n",
    "    return data.loc[~data[\"worker_id\"].isin(ids_to_exclude)]\n",
    "\n",
    "\n",
    "def get_repeat_data(main_data):\n",
    "    return main_data.loc[main_data[\"repeat\"] == True]\n",
    "\n",
    "\n",
    "def get_simplified_race(races):\n",
    "    if len(races) == 1:\n",
    "        return races[0]\n",
    "    return \"Two or more races\"\n",
    "\n",
    "\n",
    "def are_all_elements_integers(lst):\n",
    "    return all(isinstance(item, int) for item in lst)\n",
    "\n",
    "\n",
    "def dict_to_list(dict_input):\n",
    "    max_index = max(int(key) for key in dict_input.keys())\n",
    "    sorted_items = sorted(dict_input.items(), key=lambda x: int(x[0]))\n",
    "    result_list = [None] * (max_index + 1)\n",
    "\n",
    "    for key, value in sorted_items:\n",
    "        result_list[int(key)] = value\n",
    "\n",
    "    if not are_all_elements_integers(result_list):\n",
    "        raise ValueError(f\"Not all elements are integers: {result_list}\")\n",
    "\n",
    "    return result_list\n",
    "\n",
    "\n",
    "def get_meta_data(\n",
    "    data,\n",
    "    survey_types=[\"demographic_survey\", \"debriefing_survey\"],\n",
    "    worker_id_col=\"worker_id\",\n",
    "    expected_repeat_pairs=30,\n",
    "    reliability_must_be_above=0,\n",
    "    seriousness_threshold=70,\n",
    "    min_pixel_count=480_000,\n",
    "):\n",
    "    \"\"\"\n",
    "     Processes experiment data and returns the main experiment data.\n",
    "\n",
    "\n",
    "\n",
    "    Args:\n",
    "\n",
    "        data (pd.DataFrame): Raw DataFrame from experiment data.\n",
    "\n",
    "        include_repeat_data (bool): If True, includes repeat trials for reliable\n",
    "\n",
    "                                     participants in the output 'main_data'.\n",
    "\n",
    "                                     If False, removes repeat trials.\n",
    "\n",
    "        expected_repeat_pairs (int): Expected number of stimulus pairs for reliability check.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        pd.DataFrame: Filtered and cleaned DataFrame for all participants.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    " \n",
    "    id_columns = ['anon_id', 'worker_id', 'sona_id']\n",
    "    available_ids = [col for col in id_columns if col in data.columns]\n",
    "    if not available_ids:\n",
    "        raise ValueError(\"No valid ID columns found in data\")\n",
    "    primary_id = available_ids[0]\n",
    "    \n",
    "\n",
    "    trial_phases = [\"main\", \"main_repeat\"]\n",
    "    main_data = data.loc[data[\"experiment_phase\"].isin(trial_phases)].copy()\n",
    "    \n",
    "\n",
    "    if \"start_time\" in main_data.columns:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(main_data[\"start_time\"]):\n",
    "            main_data[\"start_time\"] = pd.to_datetime(main_data[\"start_time\"], format='ISO8601')\n",
    "        min_start_times = main_data.groupby(primary_id)[\"start_time\"].min()\n",
    "        main_data = main_data.merge(min_start_times.rename(\"min_start_time\"), on=primary_id, how='left')\n",
    "        df_first_session = main_data.loc[main_data[\"start_time\"] == main_data[\"min_start_time\"]].copy()\n",
    "        df_first_session = df_first_session.drop(columns=[\"min_start_time\"])\n",
    "    else:\n",
    "        print(\"No start_time\")\n",
    "        df_first_session = main_data\n",
    "    \n",
    "\n",
    "    reliability_scores = calculate_reliability(df_first_session, expected_pairs=expected_repeat_pairs)\n",
    "\n",
    " \n",
    "    response_counts_by_subject = main_data.groupby(by=primary_id)[\"response_label\"].value_counts()\n",
    "    reaction_times = main_data.groupby(by=[primary_id, \"response_label\"])[\"rt\"]\n",
    "    reaction_times_by_subject_and_response = reaction_times.mean()\n",
    "    reaction_times_by_subject_and_response_stds = reaction_times.std()\n",
    "\n",
    "\n",
    "    id_to_condition = main_data.groupby(by=primary_id)[\"condition\"].first()\n",
    "    \n",
    "\n",
    "    screen_dimensions = data.groupby(primary_id)[[\"screen_width\", \"screen_height\"]].first()\n",
    "    \n",
    "\n",
    "    grouped = data.groupby(by=primary_id)\n",
    "    rows = []\n",
    "    \n",
    "    for subject_id, group in grouped:\n",
    "        survey_dataframes = []\n",
    "        \n",
    "        for survey_type in survey_types:\n",
    "            survey_data = (\n",
    "                group.query(f'experiment_phase == \"{survey_type}\"')\n",
    "                .dropna(subset=[\"form_data\"])\n",
    "                .loc[:, [primary_id, \"form_data\"]]\n",
    "            )\n",
    "            \n",
    "            if survey_data.empty:\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                survey_data.form_data = survey_data.form_data.apply(json.loads).apply(\n",
    "                    lambda x: pd.DataFrame([x])\n",
    "                )\n",
    "                survey_df = pd.concat([f for _, f in survey_data.form_data.items()])\n",
    "                survey_dataframes.append(survey_df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing survey data for {primary_id} {subject_id}, survey {survey_type}: {e}\")\n",
    "                continue\n",
    "        \n",
    "\n",
    "        row = {\n",
    "            primary_id: subject_id,\n",
    "            \"condition\": id_to_condition.get(subject_id, None),\n",
    "            **{col: group[col].iloc[0] for col in id_columns if col in group.columns}\n",
    "        }\n",
    "        \n",
    "\n",
    "        response_counts = response_counts_by_subject.get(subject_id, {})\n",
    "        for resp in [\"yes\", \"no\", \"not sure\"]:\n",
    "            row[f\"{resp}_count\"] = response_counts.get(resp, 0)\n",
    "            row[f\"{resp}_rt_mean\"] = reaction_times_by_subject_and_response.get((subject_id, resp), np.nan)\n",
    "            row[f\"{resp}_rt_sd\"] = reaction_times_by_subject_and_response_stds.get((subject_id, resp), np.nan)\n",
    "        \n",
    "\n",
    "        if survey_dataframes:\n",
    "            combined_data = pd.concat(survey_dataframes, axis=1)\n",
    "            collapsed_data = combined_data.apply(\n",
    "                lambda x: x.dropna().iloc[0] if not x.dropna().empty else None)\n",
    "            row.update(collapsed_data.to_dict())\n",
    "        \n",
    "        # Add screen dimensions\n",
    "        if subject_id in screen_dimensions.index:\n",
    "            row.update({\n",
    "                \"screen_width\": screen_dimensions.loc[subject_id, \"screen_width\"],\n",
    "                \"screen_height\": screen_dimensions.loc[subject_id, \"screen_height\"],\n",
    "                \"screen_area\": screen_dimensions.loc[subject_id, \"screen_width\"] * \n",
    "                              screen_dimensions.loc[subject_id, \"screen_height\"]\n",
    "            })\n",
    "        \n",
    "        # Add reliability score\n",
    "        if reliability_scores is not None and subject_id in reliability_scores.index:\n",
    "            row[\"reliability_score\"] = reliability_scores.loc[subject_id]\n",
    "        \n",
    "        # Set exclusion criteria\n",
    "        exclusion_flags = {\n",
    "            \"seriousness_low\": \"seriousness\" in row and row[\"seriousness\"] < seriousness_threshold,\n",
    "            \"screen_size_low\": \"screen_area\" in row and row[\"screen_area\"] < min_pixel_count,\n",
    "            \"interrupted_survey\": \"interruption\" in row and row[\"interruption\"] and \"yes\" in str(row[\"interruption\"]).lower(),\n",
    "            \"previously_participated\": \"participatedBefore\" in row and row[\"participatedBefore\"] and \n",
    "                                     \"yes\" in str(row[\"participatedBefore\"]).lower(),\n",
    "            \"reliability_low\": \"reliability_score\" in row and \n",
    "                              (row[\"reliability_score\"] <= reliability_must_be_above or \n",
    "                               np.isnan(row[\"reliability_score\"]))\n",
    "        }\n",
    "        row.update(exclusion_flags)\n",
    "        row[\"is_bad_subject\"] = any(exclusion_flags.values())\n",
    "        \n",
    "        rows.append(row)\n",
    "    \n",
    "    meta_data = pd.DataFrame.from_records(rows)\n",
    "    \n",
    "\n",
    "    if hasattr(meta_data, 'clean_names'):\n",
    "        meta_data = meta_data.clean_names(case_type=\"snake\")\n",
    "    \n",
    "\n",
    "    if \"race\" in meta_data.columns:\n",
    "        meta_data[\"simplified_race\"] = meta_data[\"race\"].apply(get_simplified_race)\n",
    "    # meta_data = meta_data[meta_data['condition'].isin(CONDITION_MAP.values())]\n",
    "    return meta_data\n",
    "\n",
    "def get_category_latents(\n",
    "    subject_data,\n",
    "    category,\n",
    "    latents,\n",
    "    category_col=\"response_label\",\n",
    "    latent_col=\"stimulus_index\",\n",
    "):\n",
    "    indexes = subject_data.loc[subject_data[category_col] == category][\n",
    "        latent_col\n",
    "    ].tolist()\n",
    "    return latents[indexes, :]\n",
    "\n",
    "\n",
    "\n",
    "def get_results(\n",
    "    subject_data,\n",
    "    # survey_data, # XXX come back to survey data stuff\n",
    "    latents,\n",
    "    positive_category=CATEGORY_LABEL_DICT[\"positive\"],\n",
    "    negative_category=CATEGORY_LABEL_DICT[\"negative\"],\n",
    "    neither_category=CATEGORY_LABEL_DICT[\"neither\"],\n",
    "    desired_num_trials=5,\n",
    "    num_response_options=3,\n",
    "    num_random_latents=30,\n",
    "    min_sd=-1.5,  # -8\n",
    "    max_sd=1.5,  # 8\n",
    "    step=0.5,  # 1\n",
    "    save_path=SAVE_PATH,\n",
    "    save_output=False,\n",
    "    seed=SEED,\n",
    "):\n",
    "    random.seed(seed)\n",
    "\n",
    "    subject_id = subject_data[\"anon_id\"].unique()[0]\n",
    "    print(f\"subject = {subject_id}\")\n",
    "    # survey_data = survey_data.loc[survey_data[\"anon_id\"] == subject_id] # xxx\n",
    "    # survey_data_dict = survey_data.to_dict(orient=\"records\")[0] # xxx\n",
    "    conditions = subject_data[\"condition\"].unique()\n",
    "    print(\"conditions:\",conditions)\n",
    "    # instruction_conditions = subject_data[\"instructions_condition\"].unique()\n",
    "    # scenarios = subject_data[\"scenario\"].unique()\n",
    "    if len(conditions) != 1:\n",
    "        raise ValueError(\"There should be exactly one condition per subject!\")\n",
    "\n",
    "    condition = conditions[0]\n",
    "    # instruction_condition = instruction_conditions[0]\n",
    "    # scenario = scenarios[0]\n",
    "\n",
    "    subject_save_path = save_path / condition / subject_id\n",
    "    reel_save_path = save_path / condition / \"reels\"\n",
    "\n",
    "    if not subject_save_path.exists():\n",
    "        subject_save_path.mkdir(parents=True)\n",
    "\n",
    "    if not reel_save_path.exists():\n",
    "        reel_save_path.mkdir(parents=True)\n",
    "\n",
    "    response_label_dict = subject_data.groupby(\"response_label\").size()\n",
    "\n",
    "    if response_label_dict.sum() < desired_num_trials:\n",
    "        raise ValueError(f\"Less than {desired_num_trials} trials!\")\n",
    "\n",
    "    has_no_neither = neither_category not in response_label_dict.keys()\n",
    "\n",
    "    if response_label_dict.shape[0] < num_response_options and not has_no_neither:\n",
    "        raise ValueError(\n",
    "            f\"Need at least one response per (unreplaceable) option! Subject: {subject_id}\"\n",
    "        )\n",
    "\n",
    "    neither_latents = None\n",
    "    possible_latent_indexes = subject_data[\"stimulus_index\"].unique().tolist()\n",
    "\n",
    "    if has_no_neither:\n",
    "        print(f\"Replacing '{neither_category}' with random average...\")\n",
    "        neither_latent_indexes = random.sample(\n",
    "            possible_latent_indexes, num_random_latents\n",
    "        )\n",
    "        neither_latents = latents[neither_latent_indexes, :]\n",
    "    else:\n",
    "        neither_latents = get_category_latents(\n",
    "            subject_data, category=neither_category, latents=latents\n",
    "        )\n",
    "\n",
    "        if (\n",
    "            neither_latents.shape[0] < num_random_latents\n",
    "            and neither_latents.shape[0] >= 1\n",
    "        ):\n",
    "            print(\n",
    "                f\"{subject_id}: only {neither_latents.shape[0]} responses in '{neither_category}' category; adding more to reach {num_random_latents}...\"\n",
    "            )\n",
    "\n",
    "\n",
    "            neither_latent_indexes = subject_data.loc[\n",
    "                subject_data[\"response_label\"] == neither_category\n",
    "            ][\"stimulus_index\"].tolist()\n",
    "            current_num_indexes = len(neither_latent_indexes)\n",
    "            possible_latent_indexes = subject_data[\"stimulus_index\"].unique().tolist()\n",
    "            remaining_possible_indexes = set(possible_latent_indexes) - set(\n",
    "                neither_latent_indexes\n",
    "            )\n",
    "            additional_neither_latent_indexes = random.sample(\n",
    "                list(remaining_possible_indexes),\n",
    "                num_random_latents - current_num_indexes,\n",
    "            )\n",
    "            if (\n",
    "                len(neither_latent_indexes)\n",
    "                + len(additional_neither_latent_indexes)\n",
    "                != num_random_latents\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    f\"Error at {subject_id}: originally {len(neither_latent_indexes)} responses, adding {len(additional_neither_latent_indexes)} != {num_random_latents} !\"\n",
    "                )\n",
    "\n",
    "            new_neither_latent_indexes = [\n",
    "                *neither_latent_indexes,\n",
    "                *additional_neither_latent_indexes,\n",
    "            ]\n",
    "            neither_latents = latents[new_neither_latent_indexes, :]\n",
    "\n",
    "    positive_latents = get_category_latents(\n",
    "        subject_data, category=positive_category, latents=latents\n",
    "    )\n",
    "    negative_latents = get_category_latents(\n",
    "        subject_data, category=negative_category, latents=latents\n",
    "    )\n",
    "    all_latents = [*positive_latents, *negative_latents, *neither_latents]\n",
    "    print(f\"Positive latents: {len(positive_latents)}\")\n",
    "    print(f\"Negative latents: {len(negative_latents)}\") \n",
    "    print(f\"Neither latents: {len(neither_latents)}\")\n",
    "    positive_mean = np.mean(np.stack(positive_latents), axis=0)\n",
    "    negative_mean = np.mean(np.stack(negative_latents), axis=0)\n",
    "    neither_mean = np.mean(np.stack(neither_latents), axis=0)\n",
    "    all_mean = np.mean(np.stack(all_latents), axis=0)\n",
    "    # XXX Come back to whether we should just look at the direction for correlations\n",
    "    # tmr_vector = positive_mean - negative_mean + neither_mean\n",
    "    tmr_vector = positive_mean - negative_mean # just the direction\n",
    "\n",
    "    images = []\n",
    "    result_latents = []\n",
    "    deepface_analyses = []\n",
    "    our_model_analyses = []\n",
    "    model_correlations = []\n",
    "    try:\n",
    "        for s in np.arange(min_sd, max_sd + step, step):\n",
    "\n",
    "            result = create_mental_representations(\n",
    "                encoder_decoder=ed,\n",
    "                positive=positive_mean,\n",
    "                negative=negative_mean,\n",
    "                neutral=neither_mean,\n",
    "                step_num=s,\n",
    "                norm=True,\n",
    "                mixed_norm=False,\n",
    "                eps=1e-8,\n",
    "                idio=False,\n",
    "            )\n",
    "\n",
    "            our_model_analysis = model.predict_all(result[\"latents\"])\n",
    "            # deepface_analysis = DeepFace.analyze(\n",
    "            #     img_path=np.array(result[\"image\"]),\n",
    "            #     actions=[\"age\", \"gender\", \"race\", \"emotion\"],\n",
    "            #     prog_bar=False,\n",
    "            # )\n",
    "            # deepface_analyses.append(deepface_analysis)\n",
    "            images.append(result[\"image\"])\n",
    "            result_latents.append(result[\"latents\"])\n",
    "            our_model_analyses.append(our_model_analysis)\n",
    "\n",
    "            # except:\n",
    "            #     display(result[\"image\"])\n",
    "            #     print(f\"{s}: error\")\n",
    "\n",
    "            if save_output:\n",
    "                result[\"image\"].save(\n",
    "                    subject_save_path / f\"{subject_id}_{condition}_{s}.jpg\"\n",
    "                )\n",
    "                np.save(\n",
    "                    subject_save_path / f\"{subject_id}_{condition}_{s}.npy\",\n",
    "                    result[\"latents\"],\n",
    "                )\n",
    "\n",
    "        reel = get_concat_h_multi_resize(images)\n",
    "\n",
    "        if save_output:\n",
    "            reel.save(reel_save_path / f\"{subject_id}_{condition}_reel.jpg\")\n",
    "\n",
    "        # first_analysis = deepface_analyses[0]\n",
    "        # last_analysis = deepface_analyses[-1]\n",
    "\n",
    "        first_face_our_model_analysis = our_model_analyses[0]\n",
    "        first_face_our_model_analysis = {\n",
    "            f\"negative_{key}\": value\n",
    "            for key, value in fir\n",
    "            \n",
    "        st_face_our_model_analysis.items()\n",
    "        }\n",
    "        last_face_our_model_analysis = our_model_analyses[-1]\n",
    "        last_face_our_model_analysis = {\n",
    "            f\"positive_{key}\": value\n",
    "            for key, value in last_face_our_model_analysis.items()\n",
    "        }\n",
    "\n",
    "        attributes = list(model.factors.keys())\n",
    "        for attribute in attributes:\n",
    "            vector = model.get_factor(attribute)[\"coefficients\"]\n",
    "            this_corr = pg.corr(vector, tmr_vector)\n",
    "            this_corr = this_corr.rename(\n",
    "                {\n",
    "                    \"r\": f\"tmr_r_{attribute}\",\n",
    "                    \"p-val\": f\"tmr_r_pval_{attribute}\",\n",
    "                    \"CI95%\": f\"tmr_r_CI95%_{attribute}\",\n",
    "                    \"BF10\": f\"tmr_r_BF10_{attribute}\",\n",
    "                    \"power\": f\"tmr_r_power_{attribute}\",\n",
    "                    \"n\": f\"tmr_r_n_{attribute}\",\n",
    "                },\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "            model_correlations.append(this_corr.to_dict(\"records\")[0])\n",
    "\n",
    "        model_correlations = {k: v for d in model_correlations for k, v in d.items()}\n",
    "\n",
    "        return {\n",
    "            # **survey_data_dict, # xxx\n",
    "            \"condition\": condition,\n",
    "            # \"scenario\": scenario,\n",
    "            # \"instructions_condition\": instruction_condition,\n",
    "            \"positive\": positive_latents,\n",
    "            \"negative\": negative_latents,\n",
    "            \"neither\": neither_latents,\n",
    "            \"positive_mean\": positive_mean,\n",
    "            \"negative_mean\": negative_mean,\n",
    "            \"neither_mean\": neither_mean,\n",
    "            \"tmr_vector\": tmr_vector,\n",
    "            \"all\": all_latents,\n",
    "            # \"images\": images, # XXX\n",
    "            # \"reel\": reel,\n",
    "            \"our_model_analyses\": our_model_analyses,\n",
    "            **first_face_our_model_analysis,\n",
    "            **last_face_our_model_analysis,\n",
    "            **model_correlations,\n",
    "            # \"deepface_analyses\": deepface_analyses,\n",
    "            # \"negative_age\": first_analysis[\"age\"],\n",
    "            # \"negative_gender\": first_analysis[\"gender\"],\n",
    "            # \"negative_dominant_race\": first_analysis[\"dominant_race\"],\n",
    "            # \"negative_dominant_emotion\": first_analysis[\"dominant_emotion\"],\n",
    "            # \"positive_age\": last_analysis[\"age\"],\n",
    "            # \"positive_gender\": last_analysis[\"gender\"],\n",
    "            # \"positive_dominant_race\": last_analysis[\"dominant_race\"],\n",
    "            # \"positive_dominant_emotion\": last_analysis[\"dominant_emotion\"],\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"error in subject: {subject_id}: {e}\")\n",
    "\n",
    "\n",
    "def get_condition_specific_labels(condition):\n",
    "    \"\"\"Returns response labels dynamically based on condition.\"\"\"\n",
    "    condition = condition.upper()  # Ensure \"gad\" -> \"GAD\"\n",
    "    return {\n",
    "        \"positive\": condition,           # e.g., \"GAD\"\n",
    "        \"negative\": f\"no {condition}\",   # e.g., \"no GAD\"\n",
    "        \"neither\": \"not sure\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a41c04-8382-4d94-9d1a-225a680ae3df",
   "metadata": {},
   "source": [
    "### Prototype Generation\n",
    "\n",
    "For each participant, we computed their Target Mental Representation (TMR) using:\n",
    "\n",
    " TMR = X - N + U \n",
    "  where X= average of images selected for yes, N= average of images selected as no, U = average of images selected as not sure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b30a40-3be2-4716-a951-ebaf39231c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mental_representations(\n",
    "    encoder_decoder,\n",
    "    positive,\n",
    "    negative,\n",
    "    neutral,\n",
    "    step_num,\n",
    "    norm=True,\n",
    "    mixed_norm=False,\n",
    "    eps=1e-8,\n",
    "    idio=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Create mental representations based on the given vectors.\n",
    "\n",
    "    Args:\n",
    "        encoder_decoder: The encoder-decoder model.\n",
    "        positive: A vector that represents the high end of the scale (or target judgment).\n",
    "        negative: A vector that represents the low end of the scale (or anti-target judgment).\n",
    "        neutral: A vector that the unique values are applied (either mean of selected \"neutrals\" or mean of a random selection).\n",
    "        step_num: An integer to multiply the vector values by (if normlized with `norm=True`, this can be interpreted as +/-SDs).\n",
    "        norm: A boolean indicating whether to normalize the vectors (default: True).\n",
    "        mixed_norm: A boolean indicating whether to use mixed normalization whereby the \"neutral\" vector is left unnormalized (default: False).\n",
    "        eps: A small value to prevent division by zero (default: 1e-8).\n",
    "        idio: A boolean indicating whether to return the idiosyncratic model vector (default: False).\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the output image, the decoded tensor, and the positive-negative vector (if idio=True).\n",
    "    \"\"\"\n",
    "    if norm:\n",
    "        # Get neutral magnitude for later unnormalization\n",
    "        neutral_magnitude = np.linalg.norm(neutral)\n",
    "\n",
    "        # Normalize both vectors\n",
    "        pos_neg = positive - negative\n",
    "        diff_norm = np.linalg.norm(pos_neg) + eps\n",
    "        normalized_diff = pos_neg / diff_norm\n",
    "\n",
    "        normalized_neutral = neutral / (np.linalg.norm(neutral) + eps)\n",
    "\n",
    "        # Combine normalized vectors\n",
    "        combined = normalized_neutral + (step_num * normalized_diff)\n",
    "\n",
    "        pos_neg_out = combined * neutral_magnitude\n",
    "\n",
    "    elif mixed_norm:\n",
    "        # pos_neg = (positive - negative) / np.linalg.norm(positive - negative)\n",
    "        # pos_neg_out = (pos_neg * step_num) + neutral\n",
    "\n",
    "        # Normalize only the difference vector\n",
    "        pos_neg = positive - negative\n",
    "        diff_norm = np.linalg.norm(pos_neg) + eps\n",
    "        normalized_diff = pos_neg / diff_norm\n",
    "\n",
    "        pos_neg_out = (step_num * normalized_diff) + neutral\n",
    "\n",
    "    else:\n",
    "        pos_neg = positive - negative\n",
    "        pos_neg_out = (pos_neg * step_num) + neutral\n",
    "\n",
    "    to_decode = torch.from_numpy(pos_neg_out).cuda().float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = encoder_decoder.decode(to_decode)\n",
    "\n",
    "    if idio:\n",
    "        return {\n",
    "            \"image\": tensor2im(out.squeeze()), \n",
    "            \"latents\": to_decode.cpu().detach().numpy(),\n",
    "            \"idio\": pos_neg\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"image\": tensor2im(out.squeeze()), \n",
    "        \"latents\": to_decode.cpu().detach().numpy()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8db75476-6852-45b9-b6e3-6d00be83225a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants after exclusion: 3\n",
      "Unique worker_ids: [nan 'TEST' '88626' '94144']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1472/4266034515.py:81: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc_data['repeat'] = rc_data['repeat'].replace(\n"
     ]
    }
   ],
   "source": [
    "rc_latents = load_rc_latents()\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "\n",
    "data[\"worker_id\"] = data[\"worker_id\"].fillna(data[\"sona_id\"])\n",
    "\n",
    "for this_id in IDS_TO_EXCLUDE:\n",
    "    if this_id: \n",
    "        data = data.loc[~data[\"worker_id\"].str.contains(this_id, case=False, na=False)]\n",
    "\n",
    "# 3. Check how many participants remain\n",
    "print(f\"Participants after exclusion: {len(data['worker_id'].dropna().unique())}\")\n",
    "print(f\"Unique worker_ids: {data['worker_id'].unique()}\")\n",
    "data = clean_data(data) # get rid of weird subjects\n",
    "meta_data = get_meta_data(data)\n",
    "good_subject_ids = meta_data.loc[~meta_data[\"is_bad_subject\"]][\"worker_id\"].tolist()\n",
    "main_data_orig = get_main_data(data, include_repeat_data=True)\n",
    "main_data = main_data_orig.loc[main_data_orig[\"worker_id\"].isin(good_subject_ids)]\n",
    "# keep only the main experiment phase\n",
    "main_data = main_data.loc[main_data[\"experiment_phase\"] == \"main\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d25a80d4-b40b-4d07-9d00-01b56e83b77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat trials per participant:\n",
      "worker_id\n",
      "88626    30\n",
      "94144    30\n",
      "Name: repeat, dtype: object\n"
     ]
    }
   ],
   "source": [
    "repeat_counts = data.groupby('worker_id')['repeat'].sum()\n",
    "print(\"Repeat trials per participant:\")\n",
    "print(repeat_counts[['88626', '94144']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c640588d-4963-4321-bf64-915f9a950752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete Trial Analysis:\n",
      "           first_presentations  repeat_presentations  unique_stimuli  \\\n",
      "worker_id                                                              \n",
      "88626                      300                    30             300   \n",
      "94144                      300                    30             300   \n",
      "\n",
      "           expected_pairs  complete_pairs  missing_first  missing_repeats  \n",
      "worker_id                                                                  \n",
      "88626                  30              30              0              270  \n",
      "94144                  30              30              0              270  \n",
      "\n",
      "Participant 88626 stimulus counts:\n",
      "stimulus_number\n",
      "34.0     2\n",
      "143.0    2\n",
      "112.0    2\n",
      "241.0    2\n",
      "69.0     2\n",
      "286.0    2\n",
      "228.0    2\n",
      "61.0     2\n",
      "236.0    2\n",
      "33.0     2\n",
      "2.0      2\n",
      "136.0    2\n",
      "157.0    2\n",
      "3.0      2\n",
      "94.0     2\n",
      "199.0    2\n",
      "201.0    2\n",
      "40.0     2\n",
      "264.0    2\n",
      "163.0    2\n",
      "298.0    2\n",
      "238.0    2\n",
      "220.0    2\n",
      "66.0     2\n",
      "48.0     2\n",
      "115.0    2\n",
      "108.0    2\n",
      "97.0     2\n",
      "83.0     2\n",
      "146.0    2\n",
      "240.0    1\n",
      "221.0    1\n",
      "42.0     1\n",
      "68.0     1\n",
      "266.0    1\n",
      "257.0    1\n",
      "282.0    1\n",
      "164.0    1\n",
      "278.0    1\n",
      "24.0     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Participant 94144 stimulus counts:\n",
      "stimulus_number\n",
      "117.0    2\n",
      "278.0    2\n",
      "243.0    2\n",
      "12.0     2\n",
      "97.0     2\n",
      "245.0    2\n",
      "61.0     2\n",
      "120.0    2\n",
      "169.0    2\n",
      "271.0    2\n",
      "2.0      2\n",
      "127.0    2\n",
      "3.0      2\n",
      "8.0      2\n",
      "62.0     2\n",
      "19.0     2\n",
      "203.0    2\n",
      "170.0    2\n",
      "186.0    2\n",
      "87.0     2\n",
      "11.0     2\n",
      "78.0     2\n",
      "75.0     2\n",
      "90.0     2\n",
      "5.0      2\n",
      "273.0    2\n",
      "295.0    2\n",
      "225.0    2\n",
      "41.0     2\n",
      "165.0    2\n",
      "191.0    1\n",
      "289.0    1\n",
      "287.0    1\n",
      "177.0    1\n",
      "257.0    1\n",
      "294.0    1\n",
      "145.0    1\n",
      "10.0     1\n",
      "49.0     1\n",
      "15.0     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Processing participant 88626\n",
      "- Found 30 properly paired stimuli\n",
      "- Reliability: r = 0.393 (based on 30 valid pairs)\n",
      "\n",
      "Processing participant 94144\n",
      "- Found 30 properly paired stimuli\n",
      "- Reliability: r = -0.107 (based on 30 valid pairs)\n",
      "\n",
      "Processing participant TEST\n",
      "- Found 30 properly paired stimuli\n",
      "- Reliability: r = 0.267 (based on 30 valid pairs)\n",
      "\n",
      "Final Pairing Results:\n",
      "  worker_id condition  reliability  valid_pairs  total_repeats\n",
      "0     88626       gad     0.392676           30             30\n",
      "1     94144       mdd    -0.107005           30             30\n",
      "2      TEST       mdd     0.267261           30             30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1472/127943966.py:5: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc_data['repeat'] = rc_data['repeat'].replace({'True': True, 'False': False, 'true': True, 'false': False})\n"
     ]
    }
   ],
   "source": [
    "def analyze_trial_counts(data):\n",
    "\n",
    "    rc_data = data[data['trial_type'] == 'single-stim-rev-cor-trial'].copy()\n",
    "\n",
    "    rc_data['repeat'] = rc_data['repeat'].replace({'True': True, 'False': False, 'true': True, 'false': False})\n",
    "    rc_data['repeat'] = rc_data['repeat'].fillna(False).astype(bool)\n",
    "    \n",
    "    trial_counts = rc_data.groupby(['worker_id', 'repeat']).size().unstack(fill_value=0)\n",
    "    trial_counts = trial_counts.rename(columns={False: 'first_presentations', True: 'repeat_presentations'})\n",
    "    \n",
    "    # Count unique stimuli\n",
    "    unique_stimuli = rc_data.groupby('worker_id')['stimulus_number'].nunique()\n",
    "    \n",
    "    # Combine results\n",
    "    analysis_df = trial_counts.join(unique_stimuli.rename('unique_stimuli'))\n",
    "    analysis_df['expected_pairs'] = 30  # Based on your experiment design\n",
    "    \n",
    "    # Calculate matching status\n",
    "    analysis_df['complete_pairs'] = analysis_df[['first_presentations', 'repeat_presentations']].min(axis=1)\n",
    "    analysis_df['missing_first'] = analysis_df['repeat_presentations'] - analysis_df['complete_pairs']\n",
    "    analysis_df['missing_repeats'] = analysis_df['first_presentations'] - analysis_df['complete_pairs']\n",
    "    \n",
    "    return analysis_df\n",
    "\n",
    "# Run analysis\n",
    "trial_analysis = analyze_trial_counts(data)\n",
    "\n",
    "# Display results for your participants\n",
    "print(\"Complete Trial Analysis:\")\n",
    "print(trial_analysis.loc[['88626', '94144']])\n",
    "\n",
    "# Detailed stimulus check for problematic cases\n",
    "for worker_id in ['88626', '94144']:\n",
    "    worker_data = data[data['worker_id'] == worker_id]\n",
    "    print(f\"\\nParticipant {worker_id} stimulus counts:\")\n",
    "    print(worker_data['stimulus_number'].value_counts().head(40))\n",
    "\n",
    "def calculate_proper_pairs(data):\n",
    "    \"\"\"Calculate properly matched pairs accounting for presentation order\"\"\"\n",
    "    # Filter and clean data\n",
    "    rc_data = data[data['trial_type'] == 'single-stim-rev-cor-trial'].copy()\n",
    "    rc_data['repeat'] = rc_data['repeat'].astype(bool)\n",
    "    \n",
    "    # Response mapping\n",
    "    response_map = {\n",
    "        \"GAD\": 1, \"no GAD\": -1, \"MDD\": 1, \"no MDD\": -1,\n",
    "        \"PTSD\": 1, \"no PTSD\": -1, \"BPD\": 1, \"no BPD\": -1,\n",
    "        \"yes\": 1, \"no\": -1, \"not sure\": 0\n",
    "    }\n",
    "    rc_data['score'] = rc_data['response_label'].map(response_map)\n",
    "    \n",
    "    # Group by participant\n",
    "    results = []\n",
    "    \n",
    "    for worker_id, worker_data in rc_data.groupby('worker_id'):\n",
    "        print(f\"\\nProcessing participant {worker_id}\")\n",
    "        \n",
    "        # Get all stimuli with exactly 2 presentations\n",
    "        stimulus_counts = worker_data['stimulus_number'].value_counts()\n",
    "        paired_stimuli = stimulus_counts[stimulus_counts == 2].index\n",
    "        \n",
    "        print(f\"- Found {len(paired_stimuli)} properly paired stimuli\")\n",
    "        \n",
    "        # Verify pairing (1 first, 1 repeat)\n",
    "        valid_pairs = []\n",
    "        for stim in paired_stimuli:\n",
    "            stim_data = worker_data[worker_data['stimulus_number'] == stim]\n",
    "            if len(stim_data[stim_data['repeat']]) == 1 and len(stim_data[~stim_data['repeat']]) == 1:\n",
    "                first = stim_data[~stim_data['repeat']].iloc[0]['score']\n",
    "                repeat = stim_data[stim_data['repeat']].iloc[0]['score']\n",
    "                valid_pairs.append((first, repeat))\n",
    "            else:\n",
    "                print(f\"- Bad pairing for stimulus {stim}:\")\n",
    "                print(f\"  First presentations: {len(stim_data[~stim_data['repeat']])}\")\n",
    "                print(f\"  Repeats: {len(stim_data[stim_data['repeat']])}\")\n",
    "        \n",
    "        # Calculate reliability\n",
    "        if len(valid_pairs) >= 2:\n",
    "            first_resp, repeat_resp = zip(*valid_pairs)\n",
    "            try:\n",
    "                corr = pearsonr(first_resp, repeat_resp)[0]\n",
    "                print(f\"- Reliability: r = {corr:.3f} (based on {len(valid_pairs)} valid pairs)\")\n",
    "                results.append({\n",
    "                    'worker_id': worker_id,\n",
    "                    'condition': worker_data['condition'].iloc[0],\n",
    "                    'reliability': corr,\n",
    "                    'valid_pairs': len(valid_pairs),\n",
    "                    'total_repeats': len(worker_data[worker_data['repeat']])\n",
    "                })\n",
    "            except:\n",
    "                print(\"- Couldn't calculate reliability\")\n",
    "        else:\n",
    "            print(\"- Insufficient valid pairs\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run analysis\n",
    "pair_results = calculate_proper_pairs(data)\n",
    "print(\"\\nFinal Pairing Results:\")\n",
    "print(pair_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92bc01d3-df54-4a19-a693-63dcb933df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate trials: 964\n"
     ]
    }
   ],
   "source": [
    "duplicates = data.duplicated(['worker_id', 'stimulus_number', 'repeat'], keep=False)\n",
    "print(f\"Duplicate trials: {len(data[duplicates])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d35d1898-7b2b-470a-868a-2cb2bec57dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b7rgecm91q5gwpo', 'pe2mm4qzcy21xoo', '8ye2tdatja9shfz',\n",
       "       '6eevj78xarytlk1', '5rj2owedhsefkas', 'chl1qgc2mjc03q0'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.anon_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79155f91-b953-4629-ab5c-659d8b9b65d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.worker_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2815562f-aa75-4edf-8e77-f7127185f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"2-participant-test-data-sona/jspsych_data_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "346686ec-9b83-454d-bdf1-88f9f858e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data.to_csv(SAVE_PATH / \"2025-04-29_subject_meta_data_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9cbafe1c-0469-4c8d-af56-eb6a08abcbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rt                                       float64\n",
       "url                                       object\n",
       "experiment_phase                          object\n",
       "refresh_count                              int64\n",
       "trial_type                                object\n",
       "trial_index                                int64\n",
       "time_elapsed                               int64\n",
       "experiment_name                           object\n",
       "assignment_id                            float64\n",
       "hit_id                                   float64\n",
       "worker_id                                 object\n",
       "turk_submit_to                           float64\n",
       "preview_mode                              object\n",
       "outside_turk                              object\n",
       "platform                                  object\n",
       "start_time                   datetime64[ns, UTC]\n",
       "condition                                 object\n",
       "end_time                     datetime64[ns, UTC]\n",
       "total_time                                 int64\n",
       "ip_address                                object\n",
       "version_date                              object\n",
       "anon_id                                   object\n",
       "debug_mode                                  bool\n",
       "completion_code                           object\n",
       "seed                                       int64\n",
       "redirect_url                              object\n",
       "worker_info                               object\n",
       "browser_events                            object\n",
       "success                                   object\n",
       "screen_width                             float64\n",
       "screen_height                            float64\n",
       "window_width                             float64\n",
       "window_height                            float64\n",
       "form_name                                 object\n",
       "form_id                                   object\n",
       "instructions_viewed_count                float64\n",
       "view_history                              object\n",
       "stimulus                                  object\n",
       "key_press                                float64\n",
       "key_name                                  object\n",
       "response_label                            object\n",
       "stimulus_number                          float64\n",
       "attention_check_on                        object\n",
       "attention_check_passed                    object\n",
       "image_shown_count                        float64\n",
       "repeat                                    object\n",
       "responses                                 object\n",
       "form_data                                 object\n",
       "sona_id                                   object\n",
       "latent                                    object\n",
       "stimulus_index                             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "569de546-6bbe-498e-a620-25d9306894e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1472/1503676477.py:81: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  rc_data['repeat'] = rc_data['repeat'].replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject = 5rj2owedhsefkas\n",
      "conditions: ['gad']\n",
      "Positive latents: 35\n",
      "Negative latents: 226\n",
      "Neither latents: 39\n",
      "subject = 6eevj78xarytlk1\n",
      "conditions: ['mdd']\n",
      "Replacing 'not sure' with random average...\n",
      "Positive latents: 126\n",
      "Negative latents: 174\n",
      "Neither latents: 2\n",
      "subject = 8ye2tdatja9shfz\n",
      "conditions: ['gad']\n",
      "Positive latents: 150\n",
      "Negative latents: 148\n",
      "Neither latents: 2\n",
      "subject = b7rgecm91q5gwpo\n",
      "conditions: ['gad']\n",
      "Replacing 'not sure' with random average...\n",
      "Positive latents: 107\n",
      "Negative latents: 193\n",
      "Neither latents: 2\n",
      "subject = chl1qgc2mjc03q0\n",
      "conditions: ['mdd']\n",
      "Positive latents: 116\n",
      "Negative latents: 150\n",
      "Neither latents: 34\n",
      "subject = pe2mm4qzcy21xoo\n",
      "conditions: ['gad']\n",
      "Replacing 'not sure' with random average...\n",
      "Positive latents: 127\n",
      "Negative latents: 173\n",
      "Neither latents: 2\n",
      "\n",
      "Processing Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>sona_id</th>\n",
       "      <th>condition</th>\n",
       "      <th>positive_count</th>\n",
       "      <th>negative_count</th>\n",
       "      <th>neither_count</th>\n",
       "      <th>status</th>\n",
       "      <th>error_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5rj2owedhsefkas</td>\n",
       "      <td>88626</td>\n",
       "      <td>gad</td>\n",
       "      <td>35</td>\n",
       "      <td>226</td>\n",
       "      <td>39</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6eevj78xarytlk1</td>\n",
       "      <td>TEST</td>\n",
       "      <td>mdd</td>\n",
       "      <td>126</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ye2tdatja9shfz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gad</td>\n",
       "      <td>150</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7rgecm91q5gwpo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gad</td>\n",
       "      <td>107</td>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chl1qgc2mjc03q0</td>\n",
       "      <td>94144</td>\n",
       "      <td>mdd</td>\n",
       "      <td>116</td>\n",
       "      <td>150</td>\n",
       "      <td>34</td>\n",
       "      <td>Success</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           anon_id sona_id condition  positive_count  negative_count  \\\n",
       "0  5rj2owedhsefkas   88626       gad              35             226   \n",
       "1  6eevj78xarytlk1    TEST       mdd             126             174   \n",
       "2  8ye2tdatja9shfz     NaN       gad             150             148   \n",
       "3  b7rgecm91q5gwpo     NaN       gad             107             193   \n",
       "4  chl1qgc2mjc03q0   94144       mdd             116             150   \n",
       "\n",
       "   neither_count   status error_message  \n",
       "0             39  Success                \n",
       "1              0  Success                \n",
       "2              2  Success                \n",
       "3              0  Success                \n",
       "4             34  Success                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">positive_count</th>\n",
       "      <th colspan=\"2\" halign=\"left\">negative_count</th>\n",
       "      <th colspan=\"2\" halign=\"left\">neither_count</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>success_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>condition</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gad</th>\n",
       "      <td>104.75</td>\n",
       "      <td>49.708316</td>\n",
       "      <td>185.0</td>\n",
       "      <td>32.954514</td>\n",
       "      <td>10.25</td>\n",
       "      <td>19.189841</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdd</th>\n",
       "      <td>121.00</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>162.0</td>\n",
       "      <td>16.970563</td>\n",
       "      <td>17.00</td>\n",
       "      <td>24.041631</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          positive_count            negative_count            neither_count  \\\n",
       "                    mean        std           mean        std          mean   \n",
       "condition                                                                     \n",
       "gad               104.75  49.708316          185.0  32.954514         10.25   \n",
       "mdd               121.00   7.071068          162.0  16.970563         17.00   \n",
       "\n",
       "                           status  \n",
       "                 std success_rate  \n",
       "condition                          \n",
       "gad        19.189841          1.0  \n",
       "mdd        24.041631          1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# First ensure all required columns exist\n",
    "if 'instructions_condition' not in data.columns:\n",
    "    data['instructions_condition'] = data.get('condition', 'default')\n",
    "\n",
    "# Clean and preprocess data\n",
    "data = clean_data(data)\n",
    "meta_data = get_meta_data(data)\n",
    "good_subject_ids = meta_data.loc[~meta_data[\"is_bad_subject\"]][\"anon_id\"].tolist()\n",
    "main_data = get_main_data(data, include_repeat_data=True)\n",
    "main_data = main_data.loc[main_data[\"anon_id\"].isin(good_subject_ids)]\n",
    "main_data = main_data.loc[main_data[\"experiment_phase\"] == \"main\"]\n",
    "\n",
    "# Create a results container DataFrame\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'anon_id', \n",
    "    'sona_id',\n",
    "    'condition', \n",
    "    'positive_count',\n",
    "    'negative_count',\n",
    "    'neither_count',\n",
    "    'status',\n",
    "    'error_message'\n",
    "])\n",
    "\n",
    "# Get sona_id mapping\n",
    "sona_mapping = main_data[['anon_id', 'sona_id']].drop_duplicates().set_index('anon_id')['sona_id']\n",
    "\n",
    "# Process each subject\n",
    "for anon_id, group in main_data.groupby(\"anon_id\"):\n",
    "    try:\n",
    "        condition = group[\"condition\"].unique()[0].lower()\n",
    "        CATEGORY_LABEL_DICT = {\n",
    "            \"positive\": condition.upper(),\n",
    "            \"negative\": f\"no {condition.upper()}\",\n",
    "            \"neither\": \"not sure\"\n",
    "        }\n",
    "        \n",
    "        response_counts = group[\"response_label\"].value_counts()\n",
    "        \n",
    "        result = get_results(\n",
    "            group,\n",
    "            latents=rc_latents,\n",
    "            positive_category=CATEGORY_LABEL_DICT[\"positive\"],\n",
    "            negative_category=CATEGORY_LABEL_DICT[\"negative\"],\n",
    "            neither_category=CATEGORY_LABEL_DICT[\"neither\"],\n",
    "            desired_num_trials=10,\n",
    "            num_random_latents=2\n",
    "        )\n",
    "        \n",
    "        # Add to results DataFrame\n",
    "        results_df.loc[len(results_df)] = {\n",
    "            'anon_id': anon_id,\n",
    "            'sona_id': sona_mapping.get(anon_id, 'N/A'),\n",
    "            'condition': condition,\n",
    "            'positive_count': response_counts.get(CATEGORY_LABEL_DICT[\"positive\"], 0),\n",
    "            'negative_count': response_counts.get(CATEGORY_LABEL_DICT[\"negative\"], 0),\n",
    "            'neither_count': response_counts.get(CATEGORY_LABEL_DICT[\"neither\"], 0),\n",
    "            'status': 'Success',\n",
    "            'error_message': ''\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        results_df.loc[len(results_df)] = {\n",
    "            'anon_id': anon_id,\n",
    "            'sona_id': sona_mapping.get(anon_id, 'N/A'),\n",
    "            'condition': condition,\n",
    "            'positive_count': 0,\n",
    "            'negative_count': 0,\n",
    "            'neither_count': 0,\n",
    "            'status': 'Failed',\n",
    "            'error_message': str(e)\n",
    "        }\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nProcessing Results:\")\n",
    "display(results_df.head())\n",
    "\n",
    "# Show summary statistics\n",
    "print(\"\\nSummary Statistics:\")\n",
    "display(results_df.groupby('condition').agg({\n",
    "    'positive_count': ['mean', 'std'],\n",
    "    'negative_count': ['mean', 'std'],\n",
    "    'neither_count': ['mean', 'std'],\n",
    "    'status': lambda x: (x == 'Success').mean()\n",
    "}).rename(columns={'<lambda>': 'success_rate'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0148afd1-008a-4bb7-87d7-86ca12b7d25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main data shape: (1800, 52)\n",
      "Unique subjects: 6\n",
      "Condition distribution:\n",
      " condition\n",
      "gad    1200\n",
      "mdd     600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Main data shape:\", main_data.shape)\n",
    "print(\"Unique subjects:\", main_data['anon_id'].nunique())\n",
    "print(\"Condition distribution:\\n\", main_data['condition'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dc75a56-e9af-4b64-8efc-576b9e3f37a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (2028, 50)\n",
      "Columns in raw data: ['rt', 'url', 'experiment_phase', 'refresh_count', 'trial_type', 'trial_index', 'time_elapsed', 'experiment_name', 'assignment_id', 'hit_id', 'worker_id', 'turk_submit_to', 'preview_mode', 'outside_turk', 'platform', 'start_time', 'condition', 'end_time', 'total_time', 'ip_address', 'version_date', 'anon_id', 'debug_mode', 'completion_code', 'seed', 'redirect_url', 'worker_info', 'browser_events', 'success', 'screen_width', 'screen_height', 'window_width', 'window_height', 'form_name', 'form_id', 'instructions_viewed_count', 'view_history', 'stimulus', 'key_press', 'key_name', 'response_label', 'stimulus_number', 'attention_check_on', 'attention_check_passed', 'image_shown_count', 'repeat', 'responses', 'form_data', 'sona_id', 'instructions_condition']\n",
      "Unique conditions in raw data: ['gad' 'mdd']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original data shape:\", data.shape)\n",
    "print(\"Columns in raw data:\", data.columns.tolist())\n",
    "print(\"Unique conditions in raw data:\", data['condition'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c536d7eb-3a65-4145-978a-a66652e0319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Debugging subject: 5rj2owedhsefkas\n",
      "Total response counts:\n",
      "response_label\n",
      "no GAD      226\n",
      "not sure     39\n",
      "GAD          35\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Condition: gad\n",
      "\n",
      "positive category ('GAD'):\n",
      "- Count: 35\n",
      "- Sample stimulus indexes: [14, 1, 292, 103, 33]\n",
      "\n",
      "negative category ('no gad'):\n",
      "- Count: 0\n",
      "Eh bokka levu\n",
      "\n",
      "neither category ('not sure'):\n",
      "- Count: 39\n",
      "- Sample stimulus indexes: [298, 127, 185, 71, 209]\n",
      "\n",
      "Debugging subject: 6eevj78xarytlk1\n",
      "Total response counts:\n",
      "response_label\n",
      "no MDD    174\n",
      "MDD       126\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Condition: mdd\n",
      "\n",
      "positive category ('MDD'):\n",
      "- Count: 126\n",
      "- Sample stimulus indexes: [224, 195, 27, 73, 62]\n",
      "\n",
      "negative category ('no mdd'):\n",
      "- Count: 0\n",
      "Eh bokka levu\n",
      "\n",
      "neither category ('not sure'):\n",
      "- Count: 0\n",
      "Eh bokka levu\n",
      "\n",
      "Debugging subject: 8ye2tdatja9shfz\n",
      "Total response counts:\n",
      "response_label\n",
      "GAD         150\n",
      "no GAD      148\n",
      "not sure      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Condition: gad\n",
      "\n",
      "positive category ('GAD'):\n",
      "- Count: 150\n",
      "- Sample stimulus indexes: [93, 170, 195, 168, 77]\n",
      "\n",
      "negative category ('no gad'):\n",
      "- Count: 0\n",
      "Eh bokka levu\n",
      "\n",
      "neither category ('not sure'):\n",
      "- Count: 2\n",
      "- Sample stimulus indexes: [3, 265]\n",
      "\n",
      "Debugging subject: b7rgecm91q5gwpo\n",
      "Total response counts:\n",
      "response_label\n",
      "no GAD    193\n",
      "GAD       107\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Condition: gad\n",
      "\n",
      "positive category ('GAD'):\n",
      "- Count: 107\n",
      "- Sample stimulus indexes: [7, 135, 98, 114, 133]\n",
      "\n",
      "negative category ('no gad'):\n",
      "- Count: 0\n",
      "Eh bokka levu\n",
      "\n",
      "neither category ('not sure'):\n",
      "- Count: 0\n",
      "Eh bokka levu\n",
      "\n",
      "Debugging subject: chl1qgc2mjc03q0\n",
      "Total response counts:\n",
      "response_label\n",
      "no MDD      150\n",
      "MDD         116\n",
      "not sure     34\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Condition: mdd\n",
      "\n",
      "positive category ('MDD'):\n",
      "- Count: 116\n",
      "- Sample stimulus indexes: [71, 79, 118, 98, 95]\n",
      "\n",
      "negative category ('no mdd'):\n",
      "- Count: 0\n",
      "Eh bokka levu\n",
      "\n",
      "neither category ('not sure'):\n",
      "- Count: 34\n",
      "- Sample stimulus indexes: [143, 212, 216, 237, 131]\n",
      "\n",
      "Debugging subject: pe2mm4qzcy21xoo\n",
      "Total response counts:\n",
      "response_label\n",
      "no GAD    173\n",
      "GAD       127\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Condition: gad\n",
      "\n",
      "positive category ('GAD'):\n",
      "- Count: 127\n",
      "- Sample stimulus indexes: [124, 290, 152, 260, 132]\n",
      "\n",
      "negative category ('no gad'):\n",
      "- Count: 0\n",
      "Eh bokka levu\n",
      "\n",
      "neither category ('not sure'):\n",
      "- Count: 0\n",
      "Eh bokka levu\n"
     ]
    }
   ],
   "source": [
    "def debug_category_counts(subject_data, category_col=\"response_label\"):\n",
    "   \n",
    "\n",
    "    response_counts = subject_data[category_col].value_counts()\n",
    "    print(\"Total response counts:\")\n",
    "    print(response_counts)\n",
    "    \n",
    "\n",
    "    condition = subject_data[\"condition\"].unique()[0]\n",
    "    print(f\"\\nCondition: {condition}\")\n",
    "    \n",
    "    expected_categories = {\n",
    "        \"positive\": condition.upper(),\n",
    "        \"negative\": f\"no {condition.lower()}\",\n",
    "        \"neither\": \"not sure\"\n",
    "    }\n",
    "    \n",
    "    for cat_type, cat_label in expected_categories.items():\n",
    "        cat_data = subject_data[subject_data[category_col] == cat_label]\n",
    "        print(f\"\\n{cat_type} category ('{cat_label}'):\")\n",
    "        print(f\"- Count: {len(cat_data)}\")\n",
    "        \n",
    "        if len(cat_data) > 0:\n",
    "            print(\"- Sample stimulus indexes:\", cat_data[\"stimulus_index\"].head(5).tolist())\n",
    "        else:\n",
    "            print(\"Eh bokka levu\")\n",
    "    \n",
    "\n",
    "\n",
    "for anon_id, group in main_data.groupby(\"anon_id\"):\n",
    "    print(f\"\\nDebugging subject: {anon_id}\")\n",
    "    debug_category_counts(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5779cd51-8a78-40f3-ac1d-223146b01b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no GAD' 'GAD' 'not sure' 'MDD' 'no MDD']\n",
      "response_label\n",
      "no GAD      226\n",
      "not sure     39\n",
      "GAD          35\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# See what response labels exist in the data\n",
    "print(main_data['response_label'].unique())\n",
    "\n",
    "# Check responses for one problematic participant\n",
    "print(main_data[main_data['anon_id'] == '5rj2owedhsefkas']['response_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4d2f089-c94d-43bb-8c30-6a1083532091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject = 5rj2owedhsefkas\n",
      "conditions: ['gad']\n",
      "Positive latents: 35\n",
      "Negative latents: 226\n",
      "Neither latents: 39\n",
      "subject = 6eevj78xarytlk1\n",
      "conditions: ['mdd']\n",
      "Replacing 'not sure' with random average...\n",
      "Positive latents: 126\n",
      "Negative latents: 174\n",
      "Neither latents: 30\n",
      "subject = 8ye2tdatja9shfz\n",
      "conditions: ['gad']\n",
      "8ye2tdatja9shfz: only 2 responses in 'not sure' category; adding more to reach 30...\n",
      "Positive latents: 150\n",
      "Negative latents: 148\n",
      "Neither latents: 30\n",
      "subject = b7rgecm91q5gwpo\n",
      "conditions: ['gad']\n",
      "Replacing 'not sure' with random average...\n",
      "Positive latents: 107\n",
      "Negative latents: 193\n",
      "Neither latents: 30\n",
      "subject = chl1qgc2mjc03q0\n",
      "conditions: ['mdd']\n",
      "Positive latents: 116\n",
      "Negative latents: 150\n",
      "Neither latents: 34\n",
      "subject = pe2mm4qzcy21xoo\n",
      "conditions: ['gad']\n",
      "Replacing 'not sure' with random average...\n",
      "Positive latents: 127\n",
      "Negative latents: 173\n",
      "Neither latents: 30\n"
     ]
    }
   ],
   "source": [
    "grouped = main_data.groupby(by=\"anon_id\")\n",
    "\n",
    "results = {}\n",
    "errors = []\n",
    "error_outputs = []\n",
    "\n",
    "checkpoint = False\n",
    "save_output = True\n",
    "for anon_id, group in grouped:\n",
    "    condition = group['condition'].iloc[0].lower()  # e.g., \"gad\"\n",
    "    category_map = get_condition_specific_labels(condition)  # Get labels for this condition\n",
    "    \n",
    "    try:\n",
    "        results[anon_id] = get_results(\n",
    "            group,\n",
    "            latents=rc_latents,\n",
    "            positive_category=category_map[\"positive\"],  # \"GAD\"\n",
    "            negative_category=category_map[\"negative\"],  # \"no GAD\"\n",
    "            neither_category=category_map[\"neither\"],    # \"not sure\"\n",
    "            save_output=save_output\n",
    "        )\n",
    "    except Exception as e:\n",
    "        errors.append(anon_id)\n",
    "        print(f\"Error processing {anon_id} ({condition}): {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "beefdf1a-ddcd-4e9c-825e-fe008cb7ca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if conditions are being mapped correctly\n",
    "for anon_id in errors[:3]:  # First few error cases\n",
    "    group = main_data[main_data['anon_id'] == anon_id]\n",
    "    print(f\"\\nParticipant: {anon_id}\")\n",
    "    print(\"Condition:\", group['condition'].unique())\n",
    "    print(\"Response counts:\")\n",
    "    print(group['response_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a59f5497-1708-46b4-b2f1-dbd476ea2c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e07b94dd-fecd-47e1-b1cd-e48e92c61a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f7f4ed3-5d1f-4ade-a776-236a2c19c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in errors:\n",
    "    error_data = main_data.loc[main_data[\"anon_id\"] == s]\n",
    "    this_condition = error_data[\"condition\"].unique()[0]\n",
    "    # this_instruction = error_data[\"instructions_condition\"].unique()[0]\n",
    "    print(f\"{s}: {this_condition}\")\n",
    "    display(error_data.response_label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86815433-01b3-48eb-a1be-0c5a99efecf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results, orient=\"index\")\n",
    "df = df.reset_index(names=\"anon_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c687aea-acc7-4787-92ca-923b60d1889a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects: 6\n",
      "Columns: ['rt', 'url', 'experiment_phase', 'refresh_count', 'trial_type', 'trial_index', 'time_elapsed', 'experiment_name', 'assignment_id', 'hit_id', 'worker_id', 'turk_submit_to', 'preview_mode', 'outside_turk', 'platform', 'start_time', 'condition', 'end_time', 'total_time', 'ip_address', 'version_date', 'anon_id', 'debug_mode', 'completion_code', 'seed', 'redirect_url', 'worker_info', 'browser_events', 'success', 'screen_width', 'screen_height', 'window_width', 'window_height', 'form_name', 'form_id', 'instructions_viewed_count', 'view_history', 'stimulus', 'key_press', 'key_name', 'response_label', 'stimulus_number', 'attention_check_on', 'attention_check_passed', 'image_shown_count', 'repeat', 'responses', 'form_data', 'sona_id', 'instructions_condition', 'latent', 'stimulus_index']\n",
      "\n",
      "Sample response counts per subject:\n",
      "anon_id          response_label\n",
      "5rj2owedhsefkas  no GAD            226\n",
      "                 not sure           39\n",
      "                 GAD                35\n",
      "6eevj78xarytlk1  no MDD            174\n",
      "                 MDD               126\n",
      "8ye2tdatja9shfz  GAD               150\n",
      "                 no GAD            148\n",
      "                 not sure            2\n",
      "b7rgecm91q5gwpo  no GAD            193\n",
      "                 GAD               107\n",
      "chl1qgc2mjc03q0  no MDD            150\n",
      "                 MDD               116\n",
      "                 not sure           34\n",
      "pe2mm4qzcy21xoo  no GAD            173\n",
      "                 GAD               127\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total subjects: {main_data['anon_id'].nunique()}\")\n",
    "print(f\"Columns: {main_data.columns.tolist()}\")\n",
    "print(\"\\nSample response counts per subject:\")\n",
    "print(main_data.groupby('anon_id')['response_label'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba2e27af-ab43-439e-96dc-e74168b99d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results dictionary length: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Results dictionary length: {len(results)}\")\n",
    "print(f\"Dictionary contents: {results}\")\n",
    "print(f\"Total subjects in main_data: {main_data['anon_id'].nunique()}\")\n",
    "print(\"Sample subjects:\", main_data['anon_id'].unique()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5244a96d-a2b0-4840-9420-8ce54788aaf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique conditions in results dict: {'gad', 'mdd'}\n",
      "Conditions in main_data: condition\n",
      "gad    1200\n",
      "mdd     600\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique conditions in results dict:\", {v['condition'] for v in results.values()})\n",
    "print(\"Conditions in main_data:\", main_data['condition'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47e644b7-0a88-4192-892f-1c2109bba9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>condition</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neither</th>\n",
       "      <th>positive_mean</th>\n",
       "      <th>negative_mean</th>\n",
       "      <th>neither_mean</th>\n",
       "      <th>tmr_vector</th>\n",
       "      <th>all</th>\n",
       "      <th>...</th>\n",
       "      <th>tmr_r_CI95%_healthy</th>\n",
       "      <th>tmr_r_pval_healthy</th>\n",
       "      <th>tmr_r_BF10_healthy</th>\n",
       "      <th>tmr_r_power_healthy</th>\n",
       "      <th>tmr_r_n_SES</th>\n",
       "      <th>tmr_r_SES</th>\n",
       "      <th>tmr_r_CI95%_SES</th>\n",
       "      <th>tmr_r_pval_SES</th>\n",
       "      <th>tmr_r_BF10_SES</th>\n",
       "      <th>tmr_r_power_SES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5rj2owedhsefkas</td>\n",
       "      <td>gad</td>\n",
       "      <td>[[-0.0033842002, -0.2568033, -0.013955138, -0....</td>\n",
       "      <td>[[-0.049884934, -0.13330416, 0.75021434, -0.01...</td>\n",
       "      <td>[[-0.16432706, -0.13880852, -0.14999004, -0.05...</td>\n",
       "      <td>[-0.022572309, -0.058678884, 0.06322245, -0.06...</td>\n",
       "      <td>[0.032278053, -0.058037408, 0.18282458, -0.005...</td>\n",
       "      <td>[-0.049581774, -0.10543307, 0.12157784, -0.043...</td>\n",
       "      <td>[-0.054850362, -0.00064147636, -0.11960213, -0...</td>\n",
       "      <td>[[-0.0033842002, -0.2568033, -0.013955138, -0....</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.2, -0.03]</td>\n",
       "      <td>0.010012</td>\n",
       "      <td>1.511</td>\n",
       "      <td>0.732117</td>\n",
       "      <td>512</td>\n",
       "      <td>-0.138961</td>\n",
       "      <td>[-0.22, -0.05]</td>\n",
       "      <td>1.621792e-03</td>\n",
       "      <td>7.839</td>\n",
       "      <td>0.884613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6eevj78xarytlk1</td>\n",
       "      <td>mdd</td>\n",
       "      <td>[[-0.04632842, -0.097188525, 0.25203416, -0.13...</td>\n",
       "      <td>[[-0.13519934, -0.042867452, -0.39792407, -0.1...</td>\n",
       "      <td>[[-0.0686047, -0.07300926, -0.1085591, -0.1399...</td>\n",
       "      <td>[-0.006178745, -0.05480316, 0.099333666, -0.03...</td>\n",
       "      <td>[0.030745074, -0.071131654, 0.20549797, -0.004...</td>\n",
       "      <td>[0.05265927, -0.025983833, 0.19780299, -0.0086...</td>\n",
       "      <td>[-0.03692382, 0.016328495, -0.1061643, -0.0316...</td>\n",
       "      <td>[[-0.04632842, -0.097188525, 0.25203416, -0.13...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.2, -0.03]</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>1.692</td>\n",
       "      <td>0.746350</td>\n",
       "      <td>512</td>\n",
       "      <td>-0.282712</td>\n",
       "      <td>[-0.36, -0.2]</td>\n",
       "      <td>7.280091e-11</td>\n",
       "      <td>8.561e+07</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ye2tdatja9shfz</td>\n",
       "      <td>gad</td>\n",
       "      <td>[[-0.059184037, -0.0170536, -0.09908599, -0.10...</td>\n",
       "      <td>[[-0.07732462, -0.09022226, 0.43708304, -0.027...</td>\n",
       "      <td>[[-0.06835479, 0.08787264, 0.55617064, 0.00595...</td>\n",
       "      <td>[0.03816002, -0.07575642, 0.18199977, 0.001297...</td>\n",
       "      <td>[-0.0062656226, -0.053942673, 0.13479757, -0.0...</td>\n",
       "      <td>[0.006382062, -0.10676696, 0.12625815, -0.0074...</td>\n",
       "      <td>[0.04442564, -0.02181375, 0.0472022, 0.0391170...</td>\n",
       "      <td>[[-0.059184037, -0.0170536, -0.09908599, -0.10...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.03, 0.14]</td>\n",
       "      <td>0.220866</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.231860</td>\n",
       "      <td>512</td>\n",
       "      <td>-0.040129</td>\n",
       "      <td>[-0.13, 0.05]</td>\n",
       "      <td>3.648457e-01</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.148128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7rgecm91q5gwpo</td>\n",
       "      <td>gad</td>\n",
       "      <td>[[-0.25735798, 0.2724218, -0.24117568, -0.1410...</td>\n",
       "      <td>[[-0.23275177, -0.15944773, 0.46859932, -0.108...</td>\n",
       "      <td>[[-0.06633769, -0.042682704, -0.12733231, -0.0...</td>\n",
       "      <td>[0.013812826, -0.041055657, 0.16309704, -0.039...</td>\n",
       "      <td>[0.016026681, -0.07714583, 0.15969585, -0.0047...</td>\n",
       "      <td>[0.044432685, 0.014727995, 0.17279267, 0.03358...</td>\n",
       "      <td>[-0.0022138553, 0.036090173, 0.00340119, -0.03...</td>\n",
       "      <td>[[-0.25735798, 0.2724218, -0.24117568, -0.1410...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.22, -0.05]</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>5.367</td>\n",
       "      <td>0.858767</td>\n",
       "      <td>512</td>\n",
       "      <td>-0.120027</td>\n",
       "      <td>[-0.2, -0.03]</td>\n",
       "      <td>6.546121e-03</td>\n",
       "      <td>2.208</td>\n",
       "      <td>0.777407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chl1qgc2mjc03q0</td>\n",
       "      <td>mdd</td>\n",
       "      <td>[[-0.0014006937, -0.11714485, 0.81046593, -0.0...</td>\n",
       "      <td>[[-0.08235802, -0.06881271, -0.04816636, 0.058...</td>\n",
       "      <td>[[-0.08460752, 0.6828874, -0.11972974, -0.0103...</td>\n",
       "      <td>[0.030771745, -0.09429939, 0.17026405, -0.0301...</td>\n",
       "      <td>[0.0134354085, -0.07117092, 0.16436034, 0.0027...</td>\n",
       "      <td>[-0.029815054, 0.06859586, 0.11376471, -0.0619...</td>\n",
       "      <td>[0.017336337, -0.023128472, 0.005903706, -0.03...</td>\n",
       "      <td>[[-0.0014006937, -0.11714485, 0.81046593, -0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>[-0.07, 0.1]</td>\n",
       "      <td>0.688933</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.068532</td>\n",
       "      <td>512</td>\n",
       "      <td>-0.002650</td>\n",
       "      <td>[-0.09, 0.08]</td>\n",
       "      <td>9.523040e-01</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.050379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 299 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           anon_id condition  \\\n",
       "0  5rj2owedhsefkas       gad   \n",
       "1  6eevj78xarytlk1       mdd   \n",
       "2  8ye2tdatja9shfz       gad   \n",
       "3  b7rgecm91q5gwpo       gad   \n",
       "4  chl1qgc2mjc03q0       mdd   \n",
       "\n",
       "                                            positive  \\\n",
       "0  [[-0.0033842002, -0.2568033, -0.013955138, -0....   \n",
       "1  [[-0.04632842, -0.097188525, 0.25203416, -0.13...   \n",
       "2  [[-0.059184037, -0.0170536, -0.09908599, -0.10...   \n",
       "3  [[-0.25735798, 0.2724218, -0.24117568, -0.1410...   \n",
       "4  [[-0.0014006937, -0.11714485, 0.81046593, -0.0...   \n",
       "\n",
       "                                            negative  \\\n",
       "0  [[-0.049884934, -0.13330416, 0.75021434, -0.01...   \n",
       "1  [[-0.13519934, -0.042867452, -0.39792407, -0.1...   \n",
       "2  [[-0.07732462, -0.09022226, 0.43708304, -0.027...   \n",
       "3  [[-0.23275177, -0.15944773, 0.46859932, -0.108...   \n",
       "4  [[-0.08235802, -0.06881271, -0.04816636, 0.058...   \n",
       "\n",
       "                                             neither  \\\n",
       "0  [[-0.16432706, -0.13880852, -0.14999004, -0.05...   \n",
       "1  [[-0.0686047, -0.07300926, -0.1085591, -0.1399...   \n",
       "2  [[-0.06835479, 0.08787264, 0.55617064, 0.00595...   \n",
       "3  [[-0.06633769, -0.042682704, -0.12733231, -0.0...   \n",
       "4  [[-0.08460752, 0.6828874, -0.11972974, -0.0103...   \n",
       "\n",
       "                                       positive_mean  \\\n",
       "0  [-0.022572309, -0.058678884, 0.06322245, -0.06...   \n",
       "1  [-0.006178745, -0.05480316, 0.099333666, -0.03...   \n",
       "2  [0.03816002, -0.07575642, 0.18199977, 0.001297...   \n",
       "3  [0.013812826, -0.041055657, 0.16309704, -0.039...   \n",
       "4  [0.030771745, -0.09429939, 0.17026405, -0.0301...   \n",
       "\n",
       "                                       negative_mean  \\\n",
       "0  [0.032278053, -0.058037408, 0.18282458, -0.005...   \n",
       "1  [0.030745074, -0.071131654, 0.20549797, -0.004...   \n",
       "2  [-0.0062656226, -0.053942673, 0.13479757, -0.0...   \n",
       "3  [0.016026681, -0.07714583, 0.15969585, -0.0047...   \n",
       "4  [0.0134354085, -0.07117092, 0.16436034, 0.0027...   \n",
       "\n",
       "                                        neither_mean  \\\n",
       "0  [-0.049581774, -0.10543307, 0.12157784, -0.043...   \n",
       "1  [0.05265927, -0.025983833, 0.19780299, -0.0086...   \n",
       "2  [0.006382062, -0.10676696, 0.12625815, -0.0074...   \n",
       "3  [0.044432685, 0.014727995, 0.17279267, 0.03358...   \n",
       "4  [-0.029815054, 0.06859586, 0.11376471, -0.0619...   \n",
       "\n",
       "                                          tmr_vector  \\\n",
       "0  [-0.054850362, -0.00064147636, -0.11960213, -0...   \n",
       "1  [-0.03692382, 0.016328495, -0.1061643, -0.0316...   \n",
       "2  [0.04442564, -0.02181375, 0.0472022, 0.0391170...   \n",
       "3  [-0.0022138553, 0.036090173, 0.00340119, -0.03...   \n",
       "4  [0.017336337, -0.023128472, 0.005903706, -0.03...   \n",
       "\n",
       "                                                 all  ... tmr_r_CI95%_healthy  \\\n",
       "0  [[-0.0033842002, -0.2568033, -0.013955138, -0....  ...       [-0.2, -0.03]   \n",
       "1  [[-0.04632842, -0.097188525, 0.25203416, -0.13...  ...       [-0.2, -0.03]   \n",
       "2  [[-0.059184037, -0.0170536, -0.09908599, -0.10...  ...       [-0.03, 0.14]   \n",
       "3  [[-0.25735798, 0.2724218, -0.24117568, -0.1410...  ...      [-0.22, -0.05]   \n",
       "4  [[-0.0014006937, -0.11714485, 0.81046593, -0.0...  ...        [-0.07, 0.1]   \n",
       "\n",
       "   tmr_r_pval_healthy  tmr_r_BF10_healthy  tmr_r_power_healthy  tmr_r_n_SES  \\\n",
       "0            0.010012               1.511             0.732117          512   \n",
       "1            0.008817               1.692             0.746350          512   \n",
       "2            0.220866               0.117             0.231860          512   \n",
       "3            0.002453               5.367             0.858767          512   \n",
       "4            0.688933                0.06             0.068532          512   \n",
       "\n",
       "   tmr_r_SES  tmr_r_CI95%_SES  tmr_r_pval_SES  tmr_r_BF10_SES  tmr_r_power_SES  \n",
       "0  -0.138961   [-0.22, -0.05]    1.621792e-03           7.839         0.884613  \n",
       "1  -0.282712    [-0.36, -0.2]    7.280091e-11       8.561e+07         0.999998  \n",
       "2  -0.040129    [-0.13, 0.05]    3.648457e-01           0.083         0.148128  \n",
       "3  -0.120027    [-0.2, -0.03]    6.546121e-03           2.208         0.777407  \n",
       "4  -0.002650    [-0.09, 0.08]    9.523040e-01           0.055         0.050379  \n",
       "\n",
       "[5 rows x 299 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d21030d-2ab3-431b-bd0d-77ee99ed10a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anon_id</th>\n",
       "      <th>condition</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>neither</th>\n",
       "      <th>positive_mean</th>\n",
       "      <th>negative_mean</th>\n",
       "      <th>neither_mean</th>\n",
       "      <th>tmr_vector</th>\n",
       "      <th>all</th>\n",
       "      <th>...</th>\n",
       "      <th>not_sure_rt_sd</th>\n",
       "      <th>screen_width</th>\n",
       "      <th>screen_height</th>\n",
       "      <th>screen_area</th>\n",
       "      <th>seriousness_low</th>\n",
       "      <th>screen_size_low</th>\n",
       "      <th>interrupted_survey</th>\n",
       "      <th>previously_participated</th>\n",
       "      <th>reliability_low</th>\n",
       "      <th>is_bad_subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5rj2owedhsefkas</td>\n",
       "      <td>gad</td>\n",
       "      <td>[[-0.0033842002, -0.2568033, -0.013955138, -0....</td>\n",
       "      <td>[[-0.049884934, -0.13330416, 0.75021434, -0.01...</td>\n",
       "      <td>[[-0.16432706, -0.13880852, -0.14999004, -0.05...</td>\n",
       "      <td>[-0.022572309, -0.058678884, 0.06322245, -0.06...</td>\n",
       "      <td>[0.032278053, -0.058037408, 0.18282458, -0.005...</td>\n",
       "      <td>[-0.049581774, -0.10543307, 0.12157784, -0.043...</td>\n",
       "      <td>[-0.054850362, -0.00064147636, -0.11960213, -0...</td>\n",
       "      <td>[[-0.0033842002, -0.2568033, -0.013955138, -0....</td>\n",
       "      <td>...</td>\n",
       "      <td>1454.684858</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>1405320.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6eevj78xarytlk1</td>\n",
       "      <td>mdd</td>\n",
       "      <td>[[-0.04632842, -0.097188525, 0.25203416, -0.13...</td>\n",
       "      <td>[[-0.13519934, -0.042867452, -0.39792407, -0.1...</td>\n",
       "      <td>[[-0.0686047, -0.07300926, -0.1085591, -0.1399...</td>\n",
       "      <td>[-0.006178745, -0.05480316, 0.099333666, -0.03...</td>\n",
       "      <td>[0.030745074, -0.071131654, 0.20549797, -0.004...</td>\n",
       "      <td>[0.05265927, -0.025983833, 0.19780299, -0.0086...</td>\n",
       "      <td>[-0.03692382, 0.016328495, -0.1061643, -0.0316...</td>\n",
       "      <td>[[-0.04632842, -0.097188525, 0.25203416, -0.13...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>870.0</td>\n",
       "      <td>1341540.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8ye2tdatja9shfz</td>\n",
       "      <td>gad</td>\n",
       "      <td>[[-0.059184037, -0.0170536, -0.09908599, -0.10...</td>\n",
       "      <td>[[-0.07732462, -0.09022226, 0.43708304, -0.027...</td>\n",
       "      <td>[[-0.06835479, 0.08787264, 0.55617064, 0.00595...</td>\n",
       "      <td>[0.03816002, -0.07575642, 0.18199977, 0.001297...</td>\n",
       "      <td>[-0.0062656226, -0.053942673, 0.13479757, -0.0...</td>\n",
       "      <td>[0.006382062, -0.10676696, 0.12625815, -0.0074...</td>\n",
       "      <td>[0.04442564, -0.02181375, 0.0472022, 0.0391170...</td>\n",
       "      <td>[[-0.059184037, -0.0170536, -0.09908599, -0.10...</td>\n",
       "      <td>...</td>\n",
       "      <td>388.908730</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1296000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7rgecm91q5gwpo</td>\n",
       "      <td>gad</td>\n",
       "      <td>[[-0.25735798, 0.2724218, -0.24117568, -0.1410...</td>\n",
       "      <td>[[-0.23275177, -0.15944773, 0.46859932, -0.108...</td>\n",
       "      <td>[[-0.06633769, -0.042682704, -0.12733231, -0.0...</td>\n",
       "      <td>[0.013812826, -0.041055657, 0.16309704, -0.039...</td>\n",
       "      <td>[0.016026681, -0.07714583, 0.15969585, -0.0047...</td>\n",
       "      <td>[0.044432685, 0.014727995, 0.17279267, 0.03358...</td>\n",
       "      <td>[-0.0022138553, 0.036090173, 0.00340119, -0.03...</td>\n",
       "      <td>[[-0.25735798, 0.2724218, -0.24117568, -0.1410...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1296000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chl1qgc2mjc03q0</td>\n",
       "      <td>mdd</td>\n",
       "      <td>[[-0.0014006937, -0.11714485, 0.81046593, -0.0...</td>\n",
       "      <td>[[-0.08235802, -0.06881271, -0.04816636, 0.058...</td>\n",
       "      <td>[[-0.08460752, 0.6828874, -0.11972974, -0.0103...</td>\n",
       "      <td>[0.030771745, -0.09429939, 0.17026405, -0.0301...</td>\n",
       "      <td>[0.0134354085, -0.07117092, 0.16436034, 0.0027...</td>\n",
       "      <td>[-0.029815054, 0.06859586, 0.11376471, -0.0619...</td>\n",
       "      <td>[0.017336337, -0.023128472, 0.005903706, -0.03...</td>\n",
       "      <td>[[-0.0014006937, -0.11714485, 0.81046593, -0.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>538.759560</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>1296000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           anon_id condition  \\\n",
       "0  5rj2owedhsefkas       gad   \n",
       "1  6eevj78xarytlk1       mdd   \n",
       "2  8ye2tdatja9shfz       gad   \n",
       "3  b7rgecm91q5gwpo       gad   \n",
       "4  chl1qgc2mjc03q0       mdd   \n",
       "\n",
       "                                            positive  \\\n",
       "0  [[-0.0033842002, -0.2568033, -0.013955138, -0....   \n",
       "1  [[-0.04632842, -0.097188525, 0.25203416, -0.13...   \n",
       "2  [[-0.059184037, -0.0170536, -0.09908599, -0.10...   \n",
       "3  [[-0.25735798, 0.2724218, -0.24117568, -0.1410...   \n",
       "4  [[-0.0014006937, -0.11714485, 0.81046593, -0.0...   \n",
       "\n",
       "                                            negative  \\\n",
       "0  [[-0.049884934, -0.13330416, 0.75021434, -0.01...   \n",
       "1  [[-0.13519934, -0.042867452, -0.39792407, -0.1...   \n",
       "2  [[-0.07732462, -0.09022226, 0.43708304, -0.027...   \n",
       "3  [[-0.23275177, -0.15944773, 0.46859932, -0.108...   \n",
       "4  [[-0.08235802, -0.06881271, -0.04816636, 0.058...   \n",
       "\n",
       "                                             neither  \\\n",
       "0  [[-0.16432706, -0.13880852, -0.14999004, -0.05...   \n",
       "1  [[-0.0686047, -0.07300926, -0.1085591, -0.1399...   \n",
       "2  [[-0.06835479, 0.08787264, 0.55617064, 0.00595...   \n",
       "3  [[-0.06633769, -0.042682704, -0.12733231, -0.0...   \n",
       "4  [[-0.08460752, 0.6828874, -0.11972974, -0.0103...   \n",
       "\n",
       "                                       positive_mean  \\\n",
       "0  [-0.022572309, -0.058678884, 0.06322245, -0.06...   \n",
       "1  [-0.006178745, -0.05480316, 0.099333666, -0.03...   \n",
       "2  [0.03816002, -0.07575642, 0.18199977, 0.001297...   \n",
       "3  [0.013812826, -0.041055657, 0.16309704, -0.039...   \n",
       "4  [0.030771745, -0.09429939, 0.17026405, -0.0301...   \n",
       "\n",
       "                                       negative_mean  \\\n",
       "0  [0.032278053, -0.058037408, 0.18282458, -0.005...   \n",
       "1  [0.030745074, -0.071131654, 0.20549797, -0.004...   \n",
       "2  [-0.0062656226, -0.053942673, 0.13479757, -0.0...   \n",
       "3  [0.016026681, -0.07714583, 0.15969585, -0.0047...   \n",
       "4  [0.0134354085, -0.07117092, 0.16436034, 0.0027...   \n",
       "\n",
       "                                        neither_mean  \\\n",
       "0  [-0.049581774, -0.10543307, 0.12157784, -0.043...   \n",
       "1  [0.05265927, -0.025983833, 0.19780299, -0.0086...   \n",
       "2  [0.006382062, -0.10676696, 0.12625815, -0.0074...   \n",
       "3  [0.044432685, 0.014727995, 0.17279267, 0.03358...   \n",
       "4  [-0.029815054, 0.06859586, 0.11376471, -0.0619...   \n",
       "\n",
       "                                          tmr_vector  \\\n",
       "0  [-0.054850362, -0.00064147636, -0.11960213, -0...   \n",
       "1  [-0.03692382, 0.016328495, -0.1061643, -0.0316...   \n",
       "2  [0.04442564, -0.02181375, 0.0472022, 0.0391170...   \n",
       "3  [-0.0022138553, 0.036090173, 0.00340119, -0.03...   \n",
       "4  [0.017336337, -0.023128472, 0.005903706, -0.03...   \n",
       "\n",
       "                                                 all  ... not_sure_rt_sd  \\\n",
       "0  [[-0.0033842002, -0.2568033, -0.013955138, -0....  ...    1454.684858   \n",
       "1  [[-0.04632842, -0.097188525, 0.25203416, -0.13...  ...            NaN   \n",
       "2  [[-0.059184037, -0.0170536, -0.09908599, -0.10...  ...     388.908730   \n",
       "3  [[-0.25735798, 0.2724218, -0.24117568, -0.1410...  ...            NaN   \n",
       "4  [[-0.0014006937, -0.11714485, 0.81046593, -0.0...  ...     538.759560   \n",
       "\n",
       "   screen_width  screen_height  screen_area  seriousness_low  screen_size_low  \\\n",
       "0        1470.0          956.0    1405320.0            False            False   \n",
       "1        1542.0          870.0    1341540.0            False            False   \n",
       "2        1440.0          900.0    1296000.0            False            False   \n",
       "3        1440.0          900.0    1296000.0            False            False   \n",
       "4        1440.0          900.0    1296000.0            False            False   \n",
       "\n",
       "   interrupted_survey  previously_participated  reliability_low  \\\n",
       "0               False                    False            False   \n",
       "1               False                    False            False   \n",
       "2               False                    False            False   \n",
       "3               False                    False            False   \n",
       "4               False                    False            False   \n",
       "\n",
       "   is_bad_subject  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  \n",
       "\n",
       "[5 rows x 320 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.merge(df, meta_data, on=\"anon_id\", how=\"left\", suffixes=(\"\", \"_meta\"))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3faf1bf-fadd-4bf4-883d-ec746ffd503e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 320)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac3ac5ff-6d9c-454c-9af8-602415fac92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['anon_id', 'condition', 'positive', 'negative', 'neither',\n",
       "       'positive_mean', 'negative_mean', 'neither_mean', 'tmr_vector', 'all'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d40d9014-8f2f-49af-89fc-f742352292fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition='gad', 4 participants\n",
      "condition='mdd', 2 participants\n"
     ]
    }
   ],
   "source": [
    "grouped_by_condition_latents = dataset.groupby(by=\"condition\")[\n",
    "    [\n",
    "        \"positive_mean\",\n",
    "        \"negative_mean\",\n",
    "        \"neither_mean\",\n",
    "        # XXX come back to scores\n",
    "        # \"left_right_score\",        \n",
    "    ]\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for condition, group in grouped_by_condition_latents:\n",
    "    print(f\"{condition=}, {group.shape[0]} participants\")\n",
    "    pos_group_mean = np.mean(group[\"positive_mean\"].to_numpy())\n",
    "    neg_group_mean = np.mean(group[\"negative_mean\"].to_numpy())\n",
    "    neither_group_mean = np.mean(group[\"neither_mean\"].to_numpy())\n",
    "    rows.append({\n",
    "        \"condition\": condition,\n",
    "        \"positive_mean\": pos_group_mean,\n",
    "        \"negative_mean\": neg_group_mean,\n",
    "        \"neither_mean\": neither_group_mean,\n",
    "    })\n",
    "\n",
    "condition_mean_representation_df = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24eb0a3b-e0aa-46bf-a9e9-4e834769f80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "gad    4\n",
       "mdd    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all _usable_ subjects\n",
    "grouped_by_condition_latents.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "378218f2-4dc4-45bb-abd3-8b2ee5f59a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition\n",
       "gad    4\n",
       "mdd    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all subjects\n",
    "main_data.drop_duplicates(\"anon_id\").groupby(by=[\"condition\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07ceb454-8952-4c51-b1aa-c68bc95897e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condition  response_label\n",
       "gad        no GAD            740\n",
       "           GAD               419\n",
       "           not sure           41\n",
       "mdd        no MDD            324\n",
       "           MDD               242\n",
       "           not sure           34\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_data.groupby(by=[\"condition\"])[\"response_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbaae5c6-c17c-4ce0-abbc-9c8d9cfeefa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gad\n",
      "mdd\n"
     ]
    }
   ],
   "source": [
    "for (condition), group in grouped_by_condition_latents:\n",
    "    print(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2067c73-a802-4b1b-8315-2a8703184030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>positive_mean</th>\n",
       "      <th>negative_mean</th>\n",
       "      <th>neither_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gad</td>\n",
       "      <td>[0.010733629, -0.06350418, 0.14510846, -0.0311...</td>\n",
       "      <td>[0.0146316085, -0.060734272, 0.1575002, -0.015...</td>\n",
       "      <td>[0.0032673862, -0.07547915, 0.14068487, -0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdd</td>\n",
       "      <td>[0.0122965, -0.07455128, 0.13479885, -0.032876...</td>\n",
       "      <td>[0.022090241, -0.07115129, 0.18492916, -0.0006...</td>\n",
       "      <td>[0.011422108, 0.021306012, 0.15578385, -0.0352...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  condition                                      positive_mean  \\\n",
       "0       gad  [0.010733629, -0.06350418, 0.14510846, -0.0311...   \n",
       "1       mdd  [0.0122965, -0.07455128, 0.13479885, -0.032876...   \n",
       "\n",
       "                                       negative_mean  \\\n",
       "0  [0.0146316085, -0.060734272, 0.1575002, -0.015...   \n",
       "1  [0.022090241, -0.07115129, 0.18492916, -0.0006...   \n",
       "\n",
       "                                        neither_mean  \n",
       "0  [0.0032673862, -0.07547915, 0.14068487, -0.006...  \n",
       "1  [0.011422108, 0.021306012, 0.15578385, -0.0352...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_mean_representation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f547b7eb-0104-4ae1-9f12-5b9d58fe2af8",
   "metadata": {},
   "source": [
    "### Visualization of Prototypes\n",
    "\n",
    "The visualization pipeline transformed latent vectors back into face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4916ccce-9140-48bb-8677-883af8d07e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mental_representation_reel(\n",
    "    mean_dict, decoder=ed, min_sd=-2, max_sd=2, step=0.5\n",
    "):\n",
    "    images = []\n",
    "    result_latents = []\n",
    "    for s in np.arange(min_sd, max_sd + step, step):\n",
    "        result = create_mental_representations(\n",
    "            encoder_decoder=decoder,\n",
    "            positive=mean_dict[\"positive\"],\n",
    "            negative=mean_dict[\"negative\"],\n",
    "            neutral=mean_dict[\"neither\"],\n",
    "            step_num=s,\n",
    "            norm=True,\n",
    "        )\n",
    "        images.append(result[\"image\"])\n",
    "        result_latents.append(result[\"latents\"])\n",
    "\n",
    "    return {\n",
    "        \"images\": images,\n",
    "        \"latents\": result_latents,\n",
    "        \"reel\": get_concat_h_multi_resize(images),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61f086e5-1dba-4248-9ca1-9d2ee2aea901",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_average_face_reels_by_condition(df, min_sd=-2, max_sd=2, step=0.5):\n",
    "    avg_images = {}\n",
    "    for index, row in df.iterrows():\n",
    "        condition = row[\"condition\"]\n",
    "        avg_images[condition] = create_mental_representation_reel(\n",
    "            mean_dict={\n",
    "                \"positive\": row[\"positive_mean\"],\n",
    "                \"negative\": row[\"negative_mean\"],\n",
    "                \"neither\": row[\"neither_mean\"],\n",
    "            },\n",
    "            min_sd=min_sd,\n",
    "            max_sd=max_sd,\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "    \n",
    "    average_save_path = SAVE_PATH / \"averages\"\n",
    "    if not average_save_path.exists():\n",
    "        average_save_path.mkdir(parents=True)\n",
    "\n",
    "    for condition_name, v in avg_images.items():\n",
    "        v[\"reel\"].save(average_save_path / f\"{condition_name}.png\")        \n",
    "        for s, img in zip(np.arange(min_sd, max_sd + step, step), v[\"images\"]):\n",
    "            img.save(average_save_path / f\"{condition_name}_{s}.png\")\n",
    "\n",
    "\n",
    "def save_average_face_reels_by_condition_sex(df, min_sd=-2, max_sd=2, step=0.5):\n",
    "    avg_images = {}\n",
    "    for index, row in df.iterrows():\n",
    "        condition = row[\"condition\"]\n",
    "        sex = row[\"sex\"]\n",
    "        condition_sex = f\"{condition}-{sex}\"\n",
    "        avg_images[condition_sex] = create_mental_representation_reel(\n",
    "            mean_dict={\n",
    "                \"positive\": row[\"positive_mean\"],\n",
    "                \"negative\": row[\"negative_mean\"],\n",
    "                \"neither\": row[\"neither_mean\"],\n",
    "            },\n",
    "            min_sd=min_sd,\n",
    "            max_sd=max_sd,\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "    \n",
    "    average_save_path = SAVE_PATH / \"averages\"\n",
    "    if not average_save_path.exists():\n",
    "        average_save_path.mkdir(parents=True)\n",
    "\n",
    "    for condition_name, v in avg_images.items():\n",
    "        v[\"reel\"].save(average_save_path / f\"{condition_name}.png\")        \n",
    "        for s, img in zip(np.arange(min_sd, max_sd + step, step), v[\"images\"]):\n",
    "            img.save(average_save_path / f\"{condition_name}_{s}.png\")\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "def save_average_face_reels_by_condition_scenario(df, min_sd=-2, max_sd=2, step=0.5):\n",
    "    avg_images = {}\n",
    "    for index, row in df.iterrows():\n",
    "        condition = row[\"condition\"]\n",
    "        scenario = row[\"scenario\"]\n",
    "        condition_scenario = f\"{condition}-{scenario}\"\n",
    "        avg_images[condition_scenario] = create_mental_representation_reel(\n",
    "            mean_dict={\n",
    "                \"positive\": row[\"positive_mean\"],\n",
    "                \"negative\": row[\"negative_mean\"],\n",
    "                \"neither\": row[\"neither_mean\"],\n",
    "            },\n",
    "            min_sd=min_sd,\n",
    "            max_sd=max_sd,\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "    \n",
    "    average_save_path = SAVE_PATH / \"averages\"\n",
    "    if not average_save_path.exists():\n",
    "        average_save_path.mkdir(parents=True)\n",
    "\n",
    "    for condition_name, v in avg_images.items():\n",
    "        v[\"reel\"].save(average_save_path / f\"{condition_name}.png\")        \n",
    "        for s, img in zip(np.arange(min_sd, max_sd + step, step), v[\"images\"]):\n",
    "            img.save(average_save_path / f\"{condition_name}_{s}.png\")\n",
    "            \n",
    "            \n",
    "def save_average_face_reels_by_sex_condition_scenario(df, min_sd=-2, max_sd=2, step=0.5):\n",
    "    avg_images = {}\n",
    "    for index, row in df.iterrows():\n",
    "        sex = row[\"sex\"]\n",
    "        condition = row[\"condition\"]\n",
    "        scenario = row[\"scenario\"]\n",
    "        sex_condition_scenario = f\"{sex}-{condition}-{scenario}\"\n",
    "        avg_images[sex_condition_scenario] = create_mental_representation_reel(\n",
    "            mean_dict={\n",
    "                \"positive\": row[\"positive_mean\"],\n",
    "                \"negative\": row[\"negative_mean\"],\n",
    "                \"neither\": row[\"neither_mean\"],\n",
    "            },\n",
    "            min_sd=min_sd,\n",
    "            max_sd=max_sd,\n",
    "            step=step,\n",
    "        )\n",
    "\n",
    "    \n",
    "    average_save_path = SAVE_PATH / \"averages\"\n",
    "    if not average_save_path.exists():\n",
    "        average_save_path.mkdir(parents=True)\n",
    "\n",
    "    for condition_name, v in avg_images.items():\n",
    "        v[\"reel\"].save(average_save_path / f\"{condition_name}.png\")        \n",
    "        for s, img in zip(np.arange(min_sd, max_sd + step, step), v[\"images\"]):\n",
    "            img.save(average_save_path / f\"{condition_name}_{s}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a78a49f-aa03-40ec-9092-869e4c22a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sd = -1.5\n",
    "max_sd = 1.5\n",
    "step = 0.5\n",
    "save_average_face_reels_by_condition(df=condition_mean_representation_df, min_sd=min_sd, max_sd=max_sd, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b86b0-6660-4754-90fa-3d907b1892b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
